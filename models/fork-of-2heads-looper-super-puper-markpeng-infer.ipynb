{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference:\n",
    "# https://www.kaggle.com/demetrypascal/fork-of-2heads-looper-super-puper-plate/notebook\n",
    "\n",
    "kernel_mode = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.032594,
     "end_time": "2020-11-11T07:45:11.484416",
     "exception": false,
     "start_time": "2020-11-11T07:45:11.451822",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.032435,
     "end_time": "2020-11-11T07:45:11.549966",
     "exception": false,
     "start_time": "2020-11-11T07:45:11.517531",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Letâ€™s load the packages and provide some constants for our script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T07:45:11.624887Z",
     "iopub.status.busy": "2020-11-11T07:45:11.623973Z",
     "iopub.status.idle": "2020-11-11T07:45:18.923587Z",
     "shell.execute_reply": "2020-11-11T07:45:18.922330Z"
    },
    "papermill": {
     "duration": 7.340999,
     "end_time": "2020-11-11T07:45:18.923723",
     "exception": false,
     "start_time": "2020-11-11T07:45:11.582724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow.keras import layers, regularizers, Sequential, Model, backend, callbacks, optimizers, metrics, losses\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "sys.path.append('../input/iterative-stratification')\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "import pickle\n",
    "from pickle import dump, load\n",
    "import glob\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2020-11-11T07:45:19.006735Z",
     "iopub.status.busy": "2020-11-11T07:45:19.004625Z",
     "iopub.status.idle": "2020-11-11T07:45:19.007534Z",
     "shell.execute_reply": "2020-11-11T07:45:19.008095Z"
    },
    "papermill": {
     "duration": 0.050102,
     "end_time": "2020-11-11T07:45:19.008235",
     "exception": false,
     "start_time": "2020-11-11T07:45:18.958133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "PATH = \"../input/lish-moa\" if kernel_mode else \"/workspace/Kaggle/MoA\"\n",
    "model_output_folder = \"../input/2heads-looper-super-puper-markpeng\" if kernel_mode \\\n",
    "    else f\"{PATH}/2heads-looper-super-puper\"\n",
    "os.makedirs(model_output_folder, exist_ok=True)\n",
    "\n",
    "# SEEDS = [23]\n",
    "SEEDS = [23, 228, 1488, 1998, 2208, 2077, 404]\n",
    "KFOLDS = 10\n",
    "\n",
    "batch_size = 256\n",
    "# batch_size = 128\n",
    "\n",
    "label_smoothing_alpha = 0.0005\n",
    "\n",
    "P_MIN = label_smoothing_alpha\n",
    "P_MAX = 1 - P_MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T07:45:19.086097Z",
     "iopub.status.busy": "2020-11-11T07:45:19.084976Z",
     "iopub.status.idle": "2020-11-11T07:45:25.522055Z",
     "shell.execute_reply": "2020-11-11T07:45:25.518386Z"
    },
    "papermill": {
     "duration": 6.480782,
     "end_time": "2020-11-11T07:45:25.522253",
     "exception": false,
     "start_time": "2020-11-11T07:45:19.041471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import train data, drop sig_id, cp_type\n",
    "train_features = pd.read_csv(f'{PATH}/train_features.csv')\n",
    "\n",
    "non_ctl_idx = train_features.loc[\n",
    "    train_features['cp_type'] != 'ctl_vehicle'].index.to_list()\n",
    "\n",
    "# Drop training data with ctl vehicle\n",
    "tr = train_features.iloc[non_ctl_idx, :].reset_index(drop=True)\n",
    "\n",
    "test_features = pd.read_csv(f'{PATH}/test_features.csv')\n",
    "te = test_features.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets_scored = pd.read_csv(f'{PATH}/train_targets_scored.csv')\n",
    "Y = train_targets_scored.drop('sig_id', axis=1)\n",
    "Y = Y.iloc[non_ctl_idx, :].copy().reset_index(drop=True).values\n",
    "\n",
    "train_targets_nonscored = pd.read_csv(f'{PATH}/train_targets_nonscored.csv')\n",
    "Y0 = train_targets_nonscored.drop('sig_id', axis=1)\n",
    "Y0 = Y0.iloc[non_ctl_idx, :].copy().reset_index(drop=True).values\n",
    "\n",
    "sub = pd.read_csv(f'{PATH}/sample_submission.csv')\n",
    "sub.iloc[:, 1:] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.03583,
     "end_time": "2020-11-11T07:45:28.303012",
     "exception": false,
     "start_time": "2020-11-11T07:45:28.267182",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Features from t.test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.036472,
     "end_time": "2020-11-11T07:45:28.375902",
     "exception": false,
     "start_time": "2020-11-11T07:45:28.339430",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here I am getting most important predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T07:45:28.455017Z",
     "iopub.status.busy": "2020-11-11T07:45:28.454184Z",
     "iopub.status.idle": "2020-11-11T07:45:28.461483Z",
     "shell.execute_reply": "2020-11-11T07:45:28.460844Z"
    },
    "papermill": {
     "duration": 0.049565,
     "end_time": "2020-11-11T07:45:28.461601",
     "exception": false,
     "start_time": "2020-11-11T07:45:28.412036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import predictors from public kernel\n",
    "json_file_path = '../input/t-test-pca-rfe-logistic-regression/main_predictors.json' if kernel_mode \\\n",
    "    else \"/workspace/Kaggle/MoA/t-test-pca-rfe-logistic-regression/main_predictors.json\"\n",
    "\n",
    "with open(json_file_path, 'r') as j:\n",
    "    predictors = json.loads(j.read())\n",
    "    predictors = predictors['start_predictors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T07:45:28.573031Z",
     "iopub.status.busy": "2020-11-11T07:45:28.565161Z",
     "iopub.status.idle": "2020-11-11T07:45:28.576452Z",
     "shell.execute_reply": "2020-11-11T07:45:28.577030Z"
    },
    "papermill": {
     "duration": 0.0786,
     "end_time": "2020-11-11T07:45:28.577177",
     "exception": false,
     "start_time": "2020-11-11T07:45:28.498577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21948, 447)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_Xtrain = tr[predictors].copy().values\n",
    "\n",
    "second_Xtest = te[predictors].copy().values\n",
    "second_Xtrain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.036297,
     "end_time": "2020-11-11T07:45:28.650577",
     "exception": false,
     "start_time": "2020-11-11T07:45:28.614280",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Keras model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.036666,
     "end_time": "2020-11-11T07:45:28.724069",
     "exception": false,
     "start_time": "2020-11-11T07:45:28.687403",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "I got idea of **label smoothing** from this notebook: https://www.kaggle.com/kailex/moa-transfer-recipe-with-smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T07:45:28.804562Z",
     "iopub.status.busy": "2020-11-11T07:45:28.803696Z",
     "iopub.status.idle": "2020-11-11T07:45:28.808200Z",
     "shell.execute_reply": "2020-11-11T07:45:28.807569Z"
    },
    "papermill": {
     "duration": 0.047482,
     "end_time": "2020-11-11T07:45:28.808311",
     "exception": false,
     "start_time": "2020-11-11T07:45:28.760829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def logloss(y_true, y_pred):\n",
    "    y_pred = tf.clip_by_value(y_pred, P_MIN, P_MAX)\n",
    "    return -backend.mean(y_true * backend.log(y_pred) +\n",
    "                         (1 - y_true) * backend.log(1 - y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.036797,
     "end_time": "2020-11-11T07:45:28.956193",
     "exception": false,
     "start_time": "2020-11-11T07:45:28.919396",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(772, 100)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_features = [c for c in train_features.columns if c != \"sig_id\"]\n",
    "gene_experssion_features = [c for c in numeric_features if c.startswith(\"g-\")]\n",
    "cell_viability_features = [c for c in numeric_features if c.startswith(\"c-\")]\n",
    "len(gene_experssion_features), len(cell_viability_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = tr.drop(['sig_id', 'cp_type', 'cp_time', 'cp_dose'], axis=1)\n",
    "te = test_features.drop(['sig_id', 'cp_type', 'cp_time', 'cp_dose'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T07:45:29.048267Z",
     "iopub.status.busy": "2020-11-11T07:45:29.046389Z",
     "iopub.status.idle": "2020-11-11T07:45:29.049041Z",
     "shell.execute_reply": "2020-11-11T07:45:29.049614Z"
    },
    "papermill": {
     "duration": 0.056399,
     "end_time": "2020-11-11T07:45:29.049751",
     "exception": false,
     "start_time": "2020-11-11T07:45:28.993352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocessor_1(test, seed, scaler=None, pca_gs=None, pca_cs=None):\n",
    "    n_gs = 2\n",
    "    n_cs = 100\n",
    "\n",
    "    # g-mean, c-mean\n",
    "    test_g_mean = test[gene_experssion_features].mean(axis=1)\n",
    "\n",
    "    test_c_mean = test[cell_viability_features].mean(axis=1)\n",
    "\n",
    "    test_columns = test.columns.tolist()\n",
    "\n",
    "    test = np.concatenate(\n",
    "        (test, test_g_mean[:, np.newaxis], test_c_mean[:, np.newaxis]), axis=1)\n",
    "\n",
    "    # Standard Scaler for Numerical Values\n",
    "    test = pd.DataFrame(data=scaler.transform(test),\n",
    "                        columns=test_columns + [\"g_mean\", \"c_mean\"])\n",
    "    test_pca_gs = pca_gs.transform(test[gene_experssion_features].values)\n",
    "\n",
    "    test_pca_cs = pca_cs.transform(test[cell_viability_features].values)\n",
    "\n",
    "    # Append Features\n",
    "    test = np.concatenate((test, test_pca_gs, test_pca_cs), axis=1)\n",
    "\n",
    "    return test\n",
    "\n",
    "\n",
    "def preprocessor_2(test, scaler=None):\n",
    "    # Standard Scaler for Numerical Values\n",
    "    test = scaler.transform(test)\n",
    "\n",
    "    return test, scaler\n",
    "\n",
    "\n",
    "def save_pickle(obj, model_output_folder, name):\n",
    "    dump(obj, open(f\"{model_output_folder}/{name}.pkl\", 'wb'),\n",
    "         pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def load_pickle(model_output_folder, name):\n",
    "    return load(open(f\"{model_output_folder}/{name}.pkl\", 'rb'))\n",
    "\n",
    "\n",
    "def mean_logloss(y_pred, y_true):\n",
    "    logloss = (1 - y_true) * np.log(1 - y_pred +\n",
    "                                    1e-15) + y_true * np.log(y_pred + 1e-15)\n",
    "    return np.mean(-logloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21948, 872), (3982, 872))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr.shape, te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T07:45:30.295979Z",
     "iopub.status.busy": "2020-11-11T07:45:30.274930Z",
     "iopub.status.idle": "2020-11-11T08:45:30.221121Z",
     "shell.execute_reply": "2020-11-11T08:45:30.220025Z"
    },
    "papermill": {
     "duration": 3600.006513,
     "end_time": "2020-11-11T08:45:30.221259",
     "exception": false,
     "start_time": "2020-11-11T07:45:30.214746",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferencing on seed23 fold0 ......\n",
      "[[0.00062638 0.00139738 0.00256215 ... 0.00215133 0.00118474 0.00168681]\n",
      " [0.00035632 0.00282041 0.00062197 ... 0.00116035 0.00233351 0.00359165]\n",
      " [0.00111823 0.00116571 0.00234077 ... 0.00260893 0.00513931 0.00421351]\n",
      " [0.00030748 0.00038197 0.00049237 ... 0.00021168 0.0007948  0.00052682]\n",
      " [0.00435119 0.00289444 0.00288538 ... 0.00288126 0.0007065  0.00149353]]\n",
      "\n",
      "\n",
      "Inferencing on seed23 fold1 ......\n",
      "[[0.00043796 0.00087135 0.00177629 ... 0.0059837  0.00603775 0.00380701]\n",
      " [0.00099433 0.00191273 0.00115954 ... 0.00050997 0.01455158 0.00108468]\n",
      " [0.00072859 0.00028989 0.00163209 ... 0.00377872 0.00062831 0.00547929]\n",
      " [0.00150527 0.00081846 0.00254885 ... 0.00238689 0.00355374 0.00205896]\n",
      " [0.00068232 0.0011047  0.00187454 ... 0.00261347 0.00064067 0.00329006]]\n",
      "\n",
      "\n",
      "Inferencing on seed23 fold2 ......\n",
      "[[0.00078193 0.00042732 0.00251405 ... 0.00410442 0.00537843 0.00260135]\n",
      " [0.00041986 0.00105912 0.00221112 ... 0.00085451 0.00597084 0.00823114]\n",
      " [0.00225961 0.00062343 0.00217404 ... 0.00241591 0.00067006 0.00658626]\n",
      " [0.00173573 0.00090352 0.00236851 ... 0.00245255 0.00162167 0.00602719]\n",
      " [0.00095563 0.0003353  0.00194337 ... 0.00223837 0.00037146 0.00147703]]\n",
      "\n",
      "\n",
      "Inferencing on seed23 fold3 ......\n",
      "[[3.7111362e-04 6.3048885e-04 3.1821327e-03 ... 2.4160636e-03\n",
      "  4.2405901e-03 1.2356655e-03]\n",
      " [2.8972438e-04 3.6810295e-04 3.9244563e-04 ... 8.3465071e-05\n",
      "  9.5135547e-05 9.5913850e-04]\n",
      " [6.0906343e-04 1.1154886e-03 3.0367523e-03 ... 2.0556366e-03\n",
      "  2.2956729e-03 3.6362079e-03]\n",
      " [2.2655579e-03 3.3856728e-03 8.2113901e-03 ... 1.9607097e-03\n",
      "  2.5010125e-03 3.7105584e-03]\n",
      " [1.3036198e-03 1.0766607e-03 3.2199093e-03 ... 1.8228553e-03\n",
      "  2.2370006e-04 2.2112308e-03]]\n",
      "\n",
      "\n",
      "Inferencing on seed23 fold4 ......\n",
      "[[0.00054285 0.00078566 0.00211281 ... 0.00308415 0.00998901 0.00286985]\n",
      " [0.0004198  0.00371077 0.00355207 ... 0.00141318 0.00094882 0.00320055]\n",
      " [0.0004782  0.00110745 0.0029386  ... 0.00668541 0.00267041 0.00883856]\n",
      " [0.00035253 0.00044978 0.002472   ... 0.00300369 0.00325858 0.00460461]\n",
      " [0.00038406 0.00101204 0.00135788 ... 0.00263021 0.00085419 0.00122797]]\n",
      "\n",
      "\n",
      "Inferencing on seed23 fold5 ......\n",
      "[[0.00163886 0.00135802 0.00327861 ... 0.00328594 0.00664577 0.00454297]\n",
      " [0.00128655 0.00224783 0.00185293 ... 0.00303309 0.00216671 0.0018936 ]\n",
      " [0.00152849 0.00137146 0.00485839 ... 0.00415144 0.00376531 0.00331028]\n",
      " [0.00116445 0.00116003 0.00216887 ... 0.00101323 0.00134734 0.00146064]\n",
      " [0.00165581 0.00124551 0.00286887 ... 0.00287605 0.00233158 0.00604843]]\n",
      "\n",
      "\n",
      "Inferencing on seed23 fold6 ......\n",
      "[[1.2712332e-03 1.1412362e-03 1.0616023e-03 ... 1.4025430e-03\n",
      "  4.7991649e-04 3.6287450e-04]\n",
      " [3.5943747e-05 8.9466333e-04 2.3213851e-03 ... 3.3837857e-04\n",
      "  3.8991263e-03 7.8288233e-03]\n",
      " [1.1471327e-03 1.7640691e-03 3.6678829e-03 ... 3.0980767e-03\n",
      "  3.7984794e-03 4.6998733e-03]\n",
      " [2.6527604e-03 1.7312536e-03 4.7580847e-03 ... 7.7552688e-03\n",
      "  2.6150006e-03 5.4564714e-03]\n",
      " [1.4231895e-03 1.0750127e-03 8.5704605e-04 ... 1.0854594e-03\n",
      "  4.3921717e-04 3.6659901e-04]]\n",
      "\n",
      "\n",
      "Inferencing on seed23 fold7 ......\n",
      "[[0.0012197  0.00161474 0.00341892 ... 0.00386071 0.0040355  0.0027274 ]\n",
      " [0.00394296 0.00217882 0.00243641 ... 0.00488527 0.00104881 0.01124303]\n",
      " [0.00056388 0.0004815  0.00219341 ... 0.00289973 0.00349697 0.00181661]\n",
      " [0.00098483 0.00193238 0.00099593 ... 0.00140458 0.01172815 0.00210907]\n",
      " [0.00090252 0.00127077 0.00178923 ... 0.00191733 0.0017444  0.00210734]]\n",
      "\n",
      "\n",
      "Inferencing on seed23 fold8 ......\n",
      "[[0.00030305 0.0004942  0.00088528 ... 0.00122631 0.00148413 0.00100189]\n",
      " [0.00055143 0.00086304 0.00146615 ... 0.00019166 0.01360821 0.00219529]\n",
      " [0.00129568 0.00199926 0.00311128 ... 0.00389166 0.00294709 0.00453711]\n",
      " [0.00429448 0.00933185 0.00298091 ... 0.00292189 0.00125621 0.00525415]\n",
      " [0.00043932 0.00096535 0.00219077 ... 0.00101146 0.00018921 0.00046619]]\n",
      "\n",
      "\n",
      "Inferencing on seed23 fold9 ......\n",
      "[[0.0013631  0.00051229 0.00140947 ... 0.00277866 0.00622611 0.00215064]\n",
      " [0.00033427 0.0025808  0.0023915  ... 0.00129355 0.00448814 0.00498597]\n",
      " [0.00119929 0.00061843 0.00126084 ... 0.00990466 0.00590381 0.00517008]\n",
      " [0.00060881 0.00121047 0.00079811 ... 0.0025596  0.00262302 0.00084116]\n",
      " [0.00094684 0.00086974 0.00177163 ... 0.00375969 0.00093686 0.00091619]]\n",
      "\n",
      "\n",
      "Inferencing on seed228 fold0 ......\n",
      "[[0.00123037 0.00094689 0.0013604  ... 0.00197891 0.00466715 0.00440596]\n",
      " [0.00178683 0.00169053 0.00285998 ... 0.00414056 0.01294786 0.00287984]\n",
      " [0.00099297 0.00041981 0.00395619 ... 0.00349728 0.00075805 0.00384344]\n",
      " [0.00089736 0.0007753  0.00324647 ... 0.00296757 0.00075417 0.00217216]\n",
      " [0.00099513 0.00057582 0.00339513 ... 0.00496254 0.00067337 0.00142133]]\n",
      "\n",
      "\n",
      "Inferencing on seed228 fold1 ......\n",
      "[[0.00085343 0.00102521 0.00250505 ... 0.00187088 0.00114023 0.00199578]\n",
      " [0.00047944 0.00045801 0.00282334 ... 0.00058692 0.014154   0.00136566]\n",
      " [0.00242132 0.00297781 0.00381234 ... 0.00808315 0.00305917 0.01426475]\n",
      " [0.00343727 0.00318262 0.00202653 ... 0.00429776 0.00094642 0.00574823]\n",
      " [0.00232035 0.00172381 0.00199654 ... 0.00217852 0.00052141 0.00134646]]\n",
      "\n",
      "\n",
      "Inferencing on seed228 fold2 ......\n",
      "[[0.00025679 0.00055301 0.00161135 ... 0.00288699 0.0092716  0.00227522]\n",
      " [0.00088431 0.00096296 0.0011697  ... 0.00161636 0.00875057 0.00346368]\n",
      " [0.00029522 0.00123616 0.002416   ... 0.00357022 0.00209566 0.00479938]\n",
      " [0.00090342 0.00241429 0.00207459 ... 0.00157738 0.00114306 0.00322593]\n",
      " [0.00222357 0.00108756 0.0014991  ... 0.00226428 0.00015524 0.00100331]]\n",
      "\n",
      "\n",
      "Inferencing on seed228 fold3 ......\n",
      "[[0.00036155 0.00125059 0.00343256 ... 0.00388313 0.00627368 0.00379265]\n",
      " [0.00030771 0.00066151 0.00019663 ... 0.00021111 0.00069601 0.00187608]\n",
      " [0.00072299 0.00020451 0.00118693 ... 0.00995182 0.00363669 0.0037217 ]\n",
      " [0.00067244 0.00056871 0.0020569  ... 0.00413755 0.00102226 0.00329874]\n",
      " [0.00145549 0.00111443 0.00161652 ... 0.00235953 0.00076125 0.0009237 ]]\n",
      "\n",
      "\n",
      "Inferencing on seed228 fold4 ......\n",
      "[[4.5784653e-04 1.0725776e-03 4.3131150e-03 ... 4.5711515e-03\n",
      "  2.7358325e-02 2.4425338e-03]\n",
      " [9.4269417e-05 3.8513471e-04 1.5135449e-03 ... 1.6879442e-03\n",
      "  5.1487592e-04 1.6910881e-03]\n",
      " [2.7437304e-04 1.9032111e-04 1.1713643e-03 ... 3.5027673e-03\n",
      "  5.0824718e-03 1.1662507e-03]\n",
      " [3.4403295e-04 2.0459994e-04 4.6268915e-04 ... 2.8427583e-03\n",
      "  1.5393763e-03 3.5289691e-03]\n",
      " [9.1666036e-04 5.1215955e-04 1.9539590e-03 ... 9.7996718e-04\n",
      "  4.4091928e-04 8.5299037e-04]]\n",
      "\n",
      "\n",
      "Inferencing on seed228 fold5 ......\n",
      "[[0.00077852 0.00069105 0.00068788 ... 0.00100699 0.00076641 0.00051085]\n",
      " [0.00026054 0.00099976 0.00132322 ... 0.00055516 0.00711904 0.00758015]\n",
      " [0.00049513 0.00033205 0.00052083 ... 0.00297154 0.00014587 0.00206766]\n",
      " [0.00031912 0.00023923 0.00087473 ... 0.00068549 0.00016629 0.00514817]\n",
      " [0.00037375 0.00072695 0.00058624 ... 0.00049478 0.0001367  0.00043948]]\n",
      "\n",
      "\n",
      "Inferencing on seed228 fold6 ......\n",
      "[[0.00547282 0.00122752 0.00220709 ... 0.00234832 0.00122661 0.0012046 ]\n",
      " [0.00028159 0.0001253  0.00054162 ... 0.00013856 0.00095063 0.00286263]\n",
      " [0.00170759 0.0006805  0.00485131 ... 0.00339891 0.009107   0.00437493]\n",
      " [0.00076983 0.00084021 0.00177987 ... 0.00202437 0.00854437 0.00640387]\n",
      " [0.00267439 0.00227845 0.00180028 ... 0.00270869 0.00068892 0.00154852]]\n",
      "\n",
      "\n",
      "Inferencing on seed228 fold7 ......\n",
      "[[0.00292001 0.00130671 0.0010718  ... 0.00348701 0.00433481 0.00413068]\n",
      " [0.00077653 0.00182864 0.00059698 ... 0.00029611 0.00054539 0.00433695]\n",
      " [0.0004317  0.00012897 0.00178423 ... 0.00182876 0.00050995 0.00193823]\n",
      " [0.00076739 0.00031658 0.00186491 ... 0.00216572 0.00118152 0.00411969]\n",
      " [0.00349266 0.00075318 0.00108177 ... 0.00155885 0.00038534 0.00150362]]\n",
      "\n",
      "\n",
      "Inferencing on seed228 fold8 ......\n",
      "[[4.7012480e-04 2.4939107e-04 1.3214571e-03 ... 5.7098498e-03\n",
      "  1.2619309e-03 1.3425786e-03]\n",
      " [8.4501051e-05 4.6256301e-04 3.7561759e-04 ... 3.9925441e-04\n",
      "  5.4309471e-03 8.0870144e-04]\n",
      " [1.5252699e-03 5.8569957e-04 3.0541008e-03 ... 2.8598988e-03\n",
      "  1.1205151e-03 1.1700061e-03]\n",
      " [6.5189850e-04 2.4716006e-04 3.1240659e-03 ... 1.2128043e-03\n",
      "  9.8693313e-04 2.1961995e-03]\n",
      " [1.6539288e-03 4.1752926e-04 1.7641297e-03 ... 4.3393136e-03\n",
      "  8.6597184e-04 1.6438678e-03]]\n",
      "\n",
      "\n",
      "Inferencing on seed228 fold9 ......\n",
      "[[0.00083112 0.00102997 0.00112913 ... 0.00218203 0.01007644 0.00139813]\n",
      " [0.00130403 0.00040868 0.00049331 ... 0.00123464 0.00721348 0.00239361]\n",
      " [0.00082362 0.00055569 0.00603769 ... 0.00258942 0.00045117 0.00122529]\n",
      " [0.00164426 0.00084203 0.00287178 ... 0.00109287 0.00137245 0.0044546 ]\n",
      " [0.00104206 0.00219211 0.00291657 ... 0.00119398 0.00040803 0.00113686]]\n",
      "\n",
      "\n",
      "Inferencing on seed1488 fold0 ......\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00041637 0.00076366 0.00185131 ... 0.00074927 0.00080906 0.00062757]\n",
      " [0.00068896 0.00121188 0.00055628 ... 0.00127395 0.0001347  0.00816328]\n",
      " [0.0011636  0.00084701 0.00332346 ... 0.00686609 0.00115232 0.00409443]\n",
      " [0.00074673 0.00083443 0.00125869 ... 0.00120647 0.00032822 0.00361358]\n",
      " [0.00122167 0.00144062 0.00319215 ... 0.00267271 0.00139986 0.0015122 ]]\n",
      "\n",
      "\n",
      "Inferencing on seed1488 fold1 ......\n",
      "[[0.00053723 0.00158904 0.00302695 ... 0.00326372 0.00553973 0.00121735]\n",
      " [0.00055014 0.00126293 0.00050249 ... 0.00037031 0.00032316 0.00120134]\n",
      " [0.00172001 0.00094465 0.00868401 ... 0.0055094  0.00103914 0.00524251]\n",
      " [0.00197938 0.0008644  0.00155398 ... 0.00070333 0.00016051 0.00126356]\n",
      " [0.00192006 0.00174451 0.00206592 ... 0.00145532 0.00018488 0.00090535]]\n",
      "\n",
      "\n",
      "Inferencing on seed1488 fold2 ......\n",
      "[[0.00104297 0.00252677 0.00384524 ... 0.00262228 0.00304421 0.00041172]\n",
      " [0.00512925 0.00099094 0.00186214 ... 0.00074087 0.01512998 0.00092345]\n",
      " [0.00066793 0.00093589 0.00243816 ... 0.00799186 0.00052822 0.00257852]\n",
      " [0.00072638 0.00090646 0.0017032  ... 0.00102798 0.00104657 0.00290004]\n",
      " [0.00164648 0.00276441 0.00128088 ... 0.00237513 0.00037439 0.00186567]]\n",
      "\n",
      "\n",
      "Inferencing on seed1488 fold3 ......\n",
      "[[0.00221044 0.00156215 0.00125647 ... 0.00209731 0.00125574 0.00086602]\n",
      " [0.00050688 0.00174497 0.00076842 ... 0.00186029 0.00115059 0.00750172]\n",
      " [0.00023422 0.00069635 0.0032211  ... 0.00203302 0.00085376 0.00280009]\n",
      " [0.00058911 0.00065914 0.00361    ... 0.00213028 0.00480967 0.00588922]\n",
      " [0.00126268 0.00180577 0.00218052 ... 0.00134916 0.00022055 0.0013334 ]]\n",
      "\n",
      "\n",
      "Inferencing on seed1488 fold4 ......\n",
      "[[0.00120123 0.00101709 0.00183404 ... 0.00249574 0.00459466 0.00585732]\n",
      " [0.00049722 0.00138011 0.00072852 ... 0.00066642 0.00240197 0.00070721]\n",
      " [0.00134548 0.00153984 0.00903863 ... 0.01014064 0.00399993 0.02397525]\n",
      " [0.0024351  0.0003202  0.00174287 ... 0.0023882  0.00176958 0.00241518]\n",
      " [0.00064519 0.00076901 0.00076932 ... 0.0017052  0.00040165 0.00115772]]\n",
      "\n",
      "\n",
      "Inferencing on seed1488 fold5 ......\n",
      "[[0.00254536 0.00121095 0.00214029 ... 0.00224757 0.00307018 0.00357353]\n",
      " [0.00113694 0.00013882 0.00056059 ... 0.00048717 0.00616743 0.00070437]\n",
      " [0.0008479  0.00047132 0.00285964 ... 0.00376794 0.00213473 0.00233841]\n",
      " [0.00075646 0.0009676  0.00197709 ... 0.00135511 0.00194161 0.00084096]\n",
      " [0.00184749 0.00059824 0.0013227  ... 0.00110891 0.00059908 0.00110677]]\n",
      "\n",
      "\n",
      "Inferencing on seed1488 fold6 ......\n",
      "[[0.0073357  0.00281142 0.00133822 ... 0.00757028 0.00117613 0.00424535]\n",
      " [0.00146105 0.00491169 0.00143493 ... 0.00083836 0.00382655 0.00301794]\n",
      " [0.00180965 0.0007119  0.0034489  ... 0.00419923 0.01013632 0.00342807]\n",
      " [0.00052802 0.00021314 0.00250882 ... 0.00034457 0.00090459 0.00274385]\n",
      " [0.00090553 0.00034908 0.00185847 ... 0.000755   0.00028667 0.00206738]]\n",
      "\n",
      "\n",
      "Inferencing on seed1488 fold7 ......\n",
      "[[0.00111269 0.00117831 0.00174913 ... 0.00176882 0.00549679 0.00340665]\n",
      " [0.00169877 0.00291673 0.00350472 ... 0.0049428  0.0106901  0.01812216]\n",
      " [0.00026732 0.00031884 0.00182585 ... 0.00183584 0.00156628 0.00166565]\n",
      " [0.00084428 0.00042881 0.00229431 ... 0.00194137 0.00111023 0.00205155]\n",
      " [0.00071064 0.00091427 0.00222065 ... 0.00071576 0.00069772 0.00110942]]\n",
      "\n",
      "\n",
      "Inferencing on seed1488 fold8 ......\n",
      "[[0.00070135 0.0011716  0.00131138 ... 0.00123734 0.00042336 0.00180478]\n",
      " [0.00168435 0.00263872 0.00130193 ... 0.00969895 0.02059488 0.00167865]\n",
      " [0.00066085 0.00036912 0.00286842 ... 0.00533482 0.00141907 0.00256088]\n",
      " [0.00132152 0.00040495 0.00217949 ... 0.00258448 0.00193006 0.00281   ]\n",
      " [0.0013607  0.00193696 0.00269623 ... 0.00326323 0.00089839 0.00114478]]\n",
      "\n",
      "\n",
      "Inferencing on seed1488 fold9 ......\n",
      "[[0.00092264 0.00058663 0.00268536 ... 0.00281765 0.0050416  0.00268615]\n",
      " [0.00171748 0.00209527 0.00336977 ... 0.00066114 0.00345896 0.00540067]\n",
      " [0.00093756 0.00043574 0.00206223 ... 0.01080792 0.00283271 0.00309595]\n",
      " [0.001885   0.00265817 0.00356429 ... 0.00388668 0.00335001 0.00234093]\n",
      " [0.00144903 0.00120156 0.00161647 ... 0.00213056 0.00033455 0.00065382]]\n",
      "\n",
      "\n",
      "Inferencing on seed1998 fold0 ......\n",
      "[[3.9791633e-04 7.4829534e-04 6.9355947e-04 ... 1.2666627e-03\n",
      "  1.3328968e-04 6.0923526e-04]\n",
      " [4.8064787e-04 1.7753282e-03 1.4403736e-03 ... 3.6680382e-03\n",
      "  1.6258864e-03 5.6524347e-03]\n",
      " [1.0116932e-03 7.6828350e-04 1.7157526e-03 ... 3.8282659e-03\n",
      "  4.1970969e-03 5.5115293e-03]\n",
      " [4.6261353e-04 5.4578669e-04 2.2192842e-03 ... 1.2988143e-03\n",
      "  1.7290817e-03 1.6410711e-03]\n",
      " [6.0279632e-04 5.2725978e-04 1.5148686e-03 ... 1.6679571e-03\n",
      "  8.4376567e-05 6.0746627e-04]]\n",
      "\n",
      "\n",
      "Inferencing on seed1998 fold1 ......\n",
      "[[0.00155145 0.00165159 0.0026562  ... 0.00419982 0.0183609  0.00169107]\n",
      " [0.00042971 0.00344501 0.00059011 ... 0.00071552 0.00112627 0.00070567]\n",
      " [0.0026054  0.00214729 0.004802   ... 0.00495265 0.00279558 0.00834478]\n",
      " [0.0089167  0.00504177 0.00229209 ... 0.00106626 0.0011437  0.00378813]\n",
      " [0.00374326 0.00307793 0.00383185 ... 0.00180313 0.00204396 0.00262048]]\n",
      "\n",
      "\n",
      "Inferencing on seed1998 fold2 ......\n",
      "[[0.00084864 0.00327154 0.00180039 ... 0.00203127 0.00111366 0.00278771]\n",
      " [0.00037439 0.00047362 0.00045283 ... 0.00057128 0.00156221 0.00081868]\n",
      " [0.00121955 0.00039109 0.00446855 ... 0.00487133 0.00249482 0.00319545]\n",
      " [0.00105267 0.0020183  0.00461594 ... 0.00357986 0.00136203 0.00324165]\n",
      " [0.00139303 0.00166148 0.00272766 ... 0.00310298 0.00041197 0.00165338]]\n",
      "\n",
      "\n",
      "Inferencing on seed1998 fold3 ......\n",
      "[[0.00057175 0.00090801 0.0008347  ... 0.00134258 0.00231848 0.00137133]\n",
      " [0.0003956  0.00176592 0.00067971 ... 0.00346612 0.00797054 0.00183607]\n",
      " [0.00066472 0.00153476 0.00319152 ... 0.00351218 0.00150905 0.00569092]\n",
      " [0.00088123 0.00301322 0.00436273 ... 0.00178669 0.00229307 0.00425013]\n",
      " [0.00276419 0.00285627 0.00338902 ... 0.00283712 0.0007289  0.00202632]]\n",
      "\n",
      "\n",
      "Inferencing on seed1998 fold4 ......\n",
      "[[0.00038059 0.00030338 0.001658   ... 0.00074729 0.00270243 0.00373667]\n",
      " [0.00014734 0.00107799 0.00044142 ... 0.00022896 0.00533385 0.00037896]\n",
      " [0.00113968 0.0005032  0.00373926 ... 0.01184375 0.00147309 0.00403928]\n",
      " [0.00055513 0.00023452 0.00121869 ... 0.00181551 0.00052509 0.00888505]\n",
      " [0.00166095 0.00074031 0.00337283 ... 0.00675043 0.0002451  0.00073385]]\n",
      "\n",
      "\n",
      "Inferencing on seed1998 fold5 ......\n",
      "[[0.00113263 0.00079391 0.00080422 ... 0.00230933 0.00490909 0.00168213]\n",
      " [0.00036268 0.00055157 0.00025781 ... 0.00091663 0.01345886 0.00054669]\n",
      " [0.00086444 0.00055366 0.00354591 ... 0.0102332  0.00120321 0.00564562]\n",
      " [0.0002983  0.00030192 0.00567504 ... 0.00335677 0.0014985  0.00218633]\n",
      " [0.0010097  0.00144127 0.00186774 ... 0.00223971 0.00065095 0.00305306]]\n",
      "\n",
      "\n",
      "Inferencing on seed1998 fold6 ......\n",
      "[[0.00036262 0.00069326 0.00111965 ... 0.00152806 0.00163543 0.00188155]\n",
      " [0.00031126 0.00037352 0.00150021 ... 0.00112377 0.01351246 0.00362532]\n",
      " [0.00031137 0.00023431 0.00215922 ... 0.00213666 0.00066243 0.00118309]\n",
      " [0.00044502 0.00046122 0.00200965 ... 0.00130569 0.00014574 0.00105701]\n",
      " [0.00060595 0.00144859 0.00190924 ... 0.00172391 0.0002554  0.00042072]]\n",
      "\n",
      "\n",
      "Inferencing on seed1998 fold7 ......\n",
      "[[0.00120459 0.00354831 0.00321058 ... 0.001318   0.00251962 0.00223608]\n",
      " [0.00042877 0.00146583 0.00106266 ... 0.00018677 0.00282602 0.00068031]\n",
      " [0.00184051 0.00162762 0.00139624 ... 0.00546334 0.00493947 0.00448877]\n",
      " [0.00104669 0.00158695 0.00211834 ... 0.00451988 0.002068   0.00323697]\n",
      " [0.00392553 0.00249751 0.00271242 ... 0.0022758  0.00115446 0.00199558]]\n",
      "\n",
      "\n",
      "Inferencing on seed1998 fold8 ......\n",
      "[[0.00190497 0.00179896 0.00075932 ... 0.00429351 0.00243527 0.0033419 ]\n",
      " [0.00031078 0.00045376 0.00195605 ... 0.00048833 0.00671359 0.0010517 ]\n",
      " [0.00130386 0.00094289 0.005402   ... 0.00431906 0.00102683 0.00500674]\n",
      " [0.00127574 0.00145601 0.00285154 ... 0.0018694  0.00237887 0.00428356]\n",
      " [0.00088444 0.00054754 0.00107397 ... 0.00195805 0.00028705 0.00172202]]\n",
      "\n",
      "\n",
      "Inferencing on seed1998 fold9 ......\n",
      "[[0.00220144 0.0030131  0.00270208 ... 0.00153642 0.00093725 0.00144432]\n",
      " [0.00115876 0.0037803  0.0016098  ... 0.00088771 0.01036189 0.01074338]\n",
      " [0.00213321 0.00195554 0.00713593 ... 0.01207241 0.0053597  0.00399447]\n",
      " [0.00123775 0.00196412 0.00254078 ... 0.00322822 0.0017693  0.00369861]\n",
      " [0.00237524 0.00098375 0.00096843 ... 0.0028148  0.00053063 0.00137608]]\n",
      "\n",
      "\n",
      "Inferencing on seed2208 fold0 ......\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00204638 0.00113798 0.00063891 ... 0.00148389 0.00233765 0.00109445]\n",
      " [0.0019779  0.00084201 0.00062849 ... 0.00064207 0.0084047  0.00084796]\n",
      " [0.00120602 0.00119492 0.00185022 ... 0.00443862 0.00388472 0.00302889]\n",
      " [0.00219935 0.00347256 0.00602429 ... 0.00176903 0.00859255 0.00754905]\n",
      " [0.000933   0.00074738 0.00156016 ... 0.00177619 0.00116859 0.00111089]]\n",
      "\n",
      "\n",
      "Inferencing on seed2208 fold1 ......\n",
      "[[0.00090029 0.00042809 0.00075695 ... 0.00067307 0.00324794 0.00145146]\n",
      " [0.00031122 0.00011111 0.00053146 ... 0.00031583 0.00143036 0.00114015]\n",
      " [0.00158012 0.00060916 0.00282818 ... 0.00314002 0.01051789 0.00263162]\n",
      " [0.0010578  0.00051006 0.00168711 ... 0.00347083 0.00460128 0.00118598]\n",
      " [0.00219652 0.00173215 0.00210728 ... 0.00055012 0.00050442 0.00021246]]\n",
      "\n",
      "\n",
      "Inferencing on seed2208 fold2 ......\n",
      "[[0.00050057 0.00095515 0.0007046  ... 0.00070978 0.00438657 0.00101717]\n",
      " [0.00053551 0.00073265 0.00084407 ... 0.00039952 0.00197972 0.00155617]\n",
      " [0.00079254 0.00067668 0.00108984 ... 0.00857628 0.00159266 0.00262187]\n",
      " [0.000631   0.00077743 0.00091994 ... 0.00093316 0.00024513 0.0014759 ]\n",
      " [0.00063784 0.00104277 0.00130073 ... 0.00136693 0.00058465 0.00142972]]\n",
      "\n",
      "\n",
      "Inferencing on seed2208 fold3 ......\n",
      "[[0.00075472 0.00118996 0.00146828 ... 0.0012626  0.00339812 0.00090904]\n",
      " [0.00132341 0.00196009 0.00274494 ... 0.00085231 0.01061652 0.00325221]\n",
      " [0.00141129 0.00116994 0.0021898  ... 0.00267743 0.00645745 0.00175275]\n",
      " [0.00201247 0.00306047 0.0033723  ... 0.0024615  0.00291124 0.00207267]\n",
      " [0.00057738 0.00088304 0.00205259 ... 0.00155374 0.00078058 0.00074348]]\n",
      "\n",
      "\n",
      "Inferencing on seed2208 fold4 ......\n",
      "[[0.00220762 0.00180534 0.00176489 ... 0.00344888 0.00124648 0.00345303]\n",
      " [0.00082378 0.00227561 0.00146448 ... 0.00156178 0.02399884 0.00117942]\n",
      " [0.00110236 0.00049281 0.00145777 ... 0.0031597  0.00829224 0.00503924]\n",
      " [0.00214522 0.00232401 0.00555055 ... 0.00300417 0.00206952 0.0054839 ]\n",
      " [0.00115614 0.00220053 0.00282753 ... 0.0020586  0.00086011 0.00284351]]\n",
      "\n",
      "\n",
      "Inferencing on seed2208 fold5 ......\n",
      "[[0.00171727 0.00115948 0.00140766 ... 0.00129365 0.00391113 0.00131603]\n",
      " [0.00062394 0.003666   0.00210568 ... 0.00070183 0.00754319 0.00114406]\n",
      " [0.0007053  0.00056123 0.00165056 ... 0.00256099 0.00070207 0.00393294]\n",
      " [0.00076515 0.00033946 0.00090563 ... 0.00093608 0.00135074 0.00156523]\n",
      " [0.00113948 0.00106722 0.00121683 ... 0.00140364 0.0002911  0.00156183]]\n",
      "\n",
      "\n",
      "Inferencing on seed2208 fold6 ......\n",
      "[[0.00168963 0.00316821 0.00216387 ... 0.0030682  0.00560582 0.0017087 ]\n",
      " [0.00056217 0.00186101 0.00159618 ... 0.00103075 0.02964283 0.00130926]\n",
      " [0.00110444 0.00219576 0.00889525 ... 0.00849291 0.00223214 0.00633005]\n",
      " [0.00136733 0.00157588 0.00840222 ... 0.0053121  0.00809895 0.00784317]\n",
      " [0.00081802 0.00155672 0.00157418 ... 0.00190618 0.00038149 0.00114006]]\n",
      "\n",
      "\n",
      "Inferencing on seed2208 fold7 ......\n",
      "[[0.00163395 0.00067632 0.00126367 ... 0.00128391 0.00427609 0.00119384]\n",
      " [0.00023832 0.00020973 0.0022809  ... 0.00179521 0.00965581 0.00439159]\n",
      " [0.00113902 0.00041372 0.00140652 ... 0.00133902 0.00414836 0.00109581]\n",
      " [0.00128855 0.00033149 0.00176409 ... 0.0008655  0.0018243  0.00157898]\n",
      " [0.00456462 0.00202942 0.0022125  ... 0.0026449  0.00231474 0.00190156]]\n",
      "\n",
      "\n",
      "Inferencing on seed2208 fold8 ......\n",
      "[[0.00096234 0.00055779 0.00251331 ... 0.0012142  0.00533501 0.00197875]\n",
      " [0.00050846 0.00366007 0.00077992 ... 0.00054271 0.00125115 0.00472674]\n",
      " [0.00052915 0.00018513 0.00360766 ... 0.00386934 0.0012745  0.00519623]\n",
      " [0.00031766 0.00203356 0.00318971 ... 0.00124673 0.00564152 0.00267004]\n",
      " [0.002267   0.00062969 0.00530955 ... 0.00172249 0.00075121 0.0010681 ]]\n",
      "\n",
      "\n",
      "Inferencing on seed2208 fold9 ......\n",
      "[[0.00076983 0.00040034 0.00306434 ... 0.00183635 0.00374582 0.00315   ]\n",
      " [0.00113763 0.00106726 0.00120998 ... 0.00140084 0.00027669 0.00035395]\n",
      " [0.00019065 0.00041861 0.00331673 ... 0.00532637 0.00147807 0.00488842]\n",
      " [0.00045439 0.00042932 0.00126762 ... 0.00284609 0.00183365 0.00387525]\n",
      " [0.00089844 0.00068088 0.00230963 ... 0.00094394 0.00048357 0.00094844]]\n",
      "\n",
      "\n",
      "Inferencing on seed2077 fold0 ......\n",
      "[[0.00209759 0.00086367 0.00175585 ... 0.00118413 0.00273609 0.00244375]\n",
      " [0.00044421 0.00107092 0.00027022 ... 0.00060222 0.00043926 0.00063803]\n",
      " [0.00047846 0.00043018 0.00112988 ... 0.00755563 0.00393871 0.00300329]\n",
      " [0.00082181 0.00058338 0.00143743 ... 0.00244104 0.00199002 0.00113585]\n",
      " [0.00243991 0.00140479 0.00285926 ... 0.00318047 0.00087743 0.00396224]]\n",
      "\n",
      "\n",
      "Inferencing on seed2077 fold1 ......\n",
      "[[0.00087524 0.00075052 0.00215248 ... 0.00264703 0.00427349 0.00299531]\n",
      " [0.00032835 0.00024315 0.00053026 ... 0.00072926 0.00098587 0.00079743]\n",
      " [0.00124811 0.00065448 0.00355328 ... 0.00550954 0.00937526 0.00197456]\n",
      " [0.00147821 0.00065803 0.00081083 ... 0.00146039 0.0021885  0.0010915 ]\n",
      " [0.00115254 0.00065237 0.00191961 ... 0.00100352 0.00129258 0.00110706]]\n",
      "\n",
      "\n",
      "Inferencing on seed2077 fold2 ......\n",
      "[[0.00045589 0.00060136 0.0014605  ... 0.00176174 0.00122606 0.00227747]\n",
      " [0.00049292 0.0001324  0.0007693  ... 0.00070852 0.00369509 0.00179008]\n",
      " [0.00149269 0.00158205 0.00150261 ... 0.00304287 0.00684445 0.00330033]\n",
      " [0.00295429 0.0007918  0.00323302 ... 0.00620415 0.00279535 0.00735359]\n",
      " [0.0018306  0.00064535 0.00116341 ... 0.00134115 0.00047682 0.00051419]]\n",
      "\n",
      "\n",
      "Inferencing on seed2077 fold3 ......\n",
      "[[0.00286108 0.00109182 0.00248341 ... 0.00475099 0.00240456 0.00318587]\n",
      " [0.00075576 0.00130004 0.00034541 ... 0.00021638 0.00240415 0.0016071 ]\n",
      " [0.00176955 0.00074934 0.00616207 ... 0.01392083 0.00241253 0.0047047 ]\n",
      " [0.00233479 0.00137689 0.00191528 ... 0.00118027 0.00190039 0.00363048]\n",
      " [0.00225364 0.00055738 0.00544436 ... 0.00523501 0.00020419 0.00250891]]\n",
      "\n",
      "\n",
      "Inferencing on seed2077 fold4 ......\n",
      "[[2.3502973e-03 8.4848079e-04 1.8579556e-03 ... 8.7353156e-04\n",
      "  5.6022769e-03 5.1743099e-03]\n",
      " [2.5395921e-04 2.7843070e-04 5.8001070e-04 ... 3.0427022e-04\n",
      "  9.6781383e-05 4.1024169e-04]\n",
      " [2.4212728e-04 1.5313976e-03 4.3659625e-03 ... 5.0517614e-03\n",
      "  1.4613945e-03 6.2936111e-03]\n",
      " [3.0256496e-04 4.5605280e-04 1.9764842e-03 ... 8.0619886e-04\n",
      "  4.6135712e-04 1.5710442e-03]\n",
      " [1.1234531e-03 1.4780845e-03 1.2697841e-03 ... 1.1031864e-03\n",
      "  4.6021023e-04 2.7332546e-03]]\n",
      "\n",
      "\n",
      "Inferencing on seed2077 fold5 ......\n",
      "[[0.00045391 0.00029858 0.0021219  ... 0.00188538 0.00150639 0.00044075]\n",
      " [0.00124722 0.00445042 0.00129855 ... 0.00241559 0.00502163 0.00559708]\n",
      " [0.00061737 0.00047606 0.00186582 ... 0.00447256 0.00173105 0.00325698]\n",
      " [0.00092971 0.0005631  0.00189515 ... 0.00180749 0.00153478 0.00347154]\n",
      " [0.00047211 0.00042735 0.00105387 ... 0.00096576 0.00026968 0.00063191]]\n",
      "\n",
      "\n",
      "Inferencing on seed2077 fold6 ......\n",
      "[[0.00133162 0.0016963  0.00136079 ... 0.00276182 0.00169153 0.00175131]\n",
      " [0.00014073 0.00043512 0.00038462 ... 0.00114108 0.00093979 0.00053856]\n",
      " [0.00220586 0.00065396 0.00198628 ... 0.00276155 0.00214109 0.00281762]\n",
      " [0.0013658  0.00101142 0.00072642 ... 0.00112711 0.00064667 0.00466687]\n",
      " [0.00143832 0.00130058 0.00153604 ... 0.00147933 0.00217931 0.00165838]]\n",
      "\n",
      "\n",
      "Inferencing on seed2077 fold7 ......\n",
      "[[0.00123798 0.0007197  0.00229097 ... 0.00058988 0.00182671 0.0007951 ]\n",
      " [0.00138741 0.00255566 0.00294434 ... 0.00082878 0.00103779 0.0056915 ]\n",
      " [0.00056764 0.00027869 0.00184153 ... 0.00321282 0.00455596 0.00299886]\n",
      " [0.00059368 0.00070381 0.00075093 ... 0.00286172 0.00202507 0.0018082 ]\n",
      " [0.00108423 0.00064516 0.00459332 ... 0.00109426 0.00182732 0.00115242]]\n",
      "\n",
      "\n",
      "Inferencing on seed2077 fold8 ......\n",
      "[[0.00040568 0.0005461  0.0024431  ... 0.00217324 0.00563326 0.00167715]\n",
      " [0.00073823 0.00307273 0.00343475 ... 0.00166845 0.0080862  0.00157922]\n",
      " [0.00142935 0.00061918 0.00143423 ... 0.00159617 0.00076069 0.0022803 ]\n",
      " [0.00131636 0.0006684  0.00166999 ... 0.00161747 0.00228005 0.0031937 ]\n",
      " [0.00430195 0.00105893 0.00106485 ... 0.00177165 0.00037887 0.00157218]]\n",
      "\n",
      "\n",
      "Inferencing on seed2077 fold9 ......\n",
      "[[0.00088812 0.00102286 0.00188788 ... 0.00186495 0.00754406 0.00278977]\n",
      " [0.00124838 0.0007562  0.00090979 ... 0.00049957 0.02061234 0.00324751]\n",
      " [0.00113308 0.00048514 0.00096171 ... 0.00639555 0.0015716  0.00391279]\n",
      " [0.00153632 0.00181151 0.00634292 ... 0.00198243 0.00080375 0.00383651]\n",
      " [0.00056622 0.00050676 0.00233097 ... 0.00198139 0.00052732 0.00197423]]\n",
      "\n",
      "\n",
      "Inferencing on seed404 fold0 ......\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00557548 0.00195153 0.00248652 ... 0.00342366 0.00178767 0.0018387 ]\n",
      " [0.00081232 0.0019375  0.00098008 ... 0.00041475 0.00204593 0.00087728]\n",
      " [0.00061184 0.00046793 0.00204296 ... 0.00390025 0.00095449 0.00657001]\n",
      " [0.0014319  0.00282594 0.00390048 ... 0.00134808 0.00097792 0.00351321]\n",
      " [0.00083724 0.00269259 0.00250249 ... 0.00103952 0.000378   0.00402767]]\n",
      "\n",
      "\n",
      "Inferencing on seed404 fold1 ......\n",
      "[[0.00118746 0.00261698 0.00133018 ... 0.00185213 0.00260876 0.00411207]\n",
      " [0.00020632 0.0003831  0.00087567 ... 0.00031728 0.0105675  0.00103415]\n",
      " [0.00052676 0.0003387  0.00089782 ... 0.007139   0.00051989 0.00168848]\n",
      " [0.00036624 0.0004242  0.00162773 ... 0.00410049 0.00365159 0.00335143]\n",
      " [0.00422462 0.0033036  0.00275651 ... 0.00285165 0.00133041 0.00196757]]\n",
      "\n",
      "\n",
      "Inferencing on seed404 fold2 ......\n",
      "[[2.4624533e-04 6.4437889e-04 3.6888060e-03 ... 1.4494929e-03\n",
      "  8.0141437e-04 9.5352222e-04]\n",
      " [2.6606789e-04 2.2537904e-03 6.5190170e-04 ... 7.0158038e-03\n",
      "  7.8351488e-03 4.3963045e-03]\n",
      " [5.7564332e-04 5.3073356e-05 5.7893759e-04 ... 2.4946316e-03\n",
      "  5.3510431e-04 5.9067416e-03]\n",
      " [2.9638887e-04 1.5170951e-04 6.5451977e-04 ... 9.6506276e-04\n",
      "  1.0684278e-03 1.0220138e-03]\n",
      " [9.7408186e-04 1.0120218e-03 4.8106904e-03 ... 8.5486227e-04\n",
      "  9.0757290e-05 9.4888615e-04]]\n",
      "\n",
      "\n",
      "Inferencing on seed404 fold3 ......\n",
      "[[0.00063655 0.00112173 0.00179167 ... 0.00131731 0.00120859 0.00172262]\n",
      " [0.0004204  0.00034127 0.0006163  ... 0.00047959 0.02179711 0.00229249]\n",
      " [0.00098967 0.0020055  0.00594418 ... 0.01215007 0.00049374 0.00686263]\n",
      " [0.00028296 0.00139399 0.00163139 ... 0.00253172 0.00750372 0.00520756]\n",
      " [0.00327594 0.004124   0.01422162 ... 0.0066517  0.00014442 0.00201746]]\n",
      "\n",
      "\n",
      "Inferencing on seed404 fold4 ......\n",
      "[[0.0010452  0.00042963 0.00388783 ... 0.00262433 0.0063399  0.00377341]\n",
      " [0.00055531 0.00253907 0.00156092 ... 0.00213954 0.01702389 0.00258245]\n",
      " [0.00093959 0.00046537 0.00304024 ... 0.00569343 0.00972866 0.00330225]\n",
      " [0.00068875 0.0007233  0.00262939 ... 0.00317031 0.00181365 0.00295567]\n",
      " [0.00079383 0.00025914 0.00270624 ... 0.00229427 0.00076366 0.00138974]]\n",
      "\n",
      "\n",
      "Inferencing on seed404 fold5 ......\n",
      "[[0.00161481 0.00127863 0.00235684 ... 0.00204525 0.00178432 0.00098009]\n",
      " [0.00094229 0.00221685 0.00114838 ... 0.00086893 0.00195443 0.00247262]\n",
      " [0.00175513 0.00163389 0.00204521 ... 0.00267731 0.0037618  0.00186443]\n",
      " [0.0017418  0.0043347  0.00534916 ... 0.00123176 0.0021932  0.00392713]\n",
      " [0.00178473 0.00358675 0.00316334 ... 0.00135487 0.00143775 0.00128678]]\n",
      "\n",
      "\n",
      "Inferencing on seed404 fold6 ......\n",
      "[[0.00086134 0.00107228 0.00163209 ... 0.00364614 0.00550184 0.00205572]\n",
      " [0.0003669  0.00095698 0.0003404  ... 0.0010909  0.00040767 0.0003023 ]\n",
      " [0.00169955 0.00056641 0.0055206  ... 0.00200249 0.00048859 0.00428108]\n",
      " [0.00075158 0.00047241 0.00364646 ... 0.00147942 0.00247209 0.00804754]\n",
      " [0.00179417 0.00078004 0.00162601 ... 0.00140493 0.0003305  0.00030824]]\n",
      "\n",
      "\n",
      "Inferencing on seed404 fold7 ......\n",
      "[[0.00040825 0.00015598 0.00138709 ... 0.00240638 0.00587811 0.00139861]\n",
      " [0.00012634 0.00127096 0.00082461 ... 0.00044459 0.05169525 0.00141041]\n",
      " [0.00063857 0.00049236 0.00470172 ... 0.01305118 0.00290736 0.00385196]\n",
      " [0.00092743 0.00065024 0.00485695 ... 0.00380657 0.00054001 0.00284475]\n",
      " [0.00120948 0.00036794 0.00270864 ... 0.00472224 0.00048905 0.00183224]]\n",
      "\n",
      "\n",
      "Inferencing on seed404 fold8 ......\n",
      "[[0.00170664 0.00079185 0.00134929 ... 0.0038943  0.00350218 0.00366235]\n",
      " [0.00060481 0.00187834 0.00266236 ... 0.00017312 0.00071052 0.00374938]\n",
      " [0.00058423 0.00155326 0.00459213 ... 0.00563164 0.00117817 0.00360138]\n",
      " [0.00078863 0.0010524  0.00428534 ... 0.00154996 0.00210395 0.00268924]\n",
      " [0.00070817 0.00081818 0.00256304 ... 0.0016874  0.00030778 0.00153602]]\n",
      "\n",
      "\n",
      "Inferencing on seed404 fold9 ......\n",
      "[[4.9464544e-04 3.9883939e-04 8.5059722e-04 ... 7.7951013e-04\n",
      "  5.7997108e-03 1.5796385e-03]\n",
      " [5.0993141e-04 7.7072234e-04 1.4479533e-03 ... 2.9722473e-04\n",
      "  3.0247858e-02 2.1166489e-03]\n",
      " [4.2941162e-04 8.7833742e-04 2.8851740e-03 ... 3.6841668e-03\n",
      "  5.6142709e-04 3.0333444e-03]\n",
      " [2.4482151e-04 9.5849682e-04 3.2881328e-03 ... 3.2835430e-03\n",
      "  2.6829322e-04 2.6123943e-03]\n",
      " [5.0961855e-04 9.9790178e-04 1.3073984e-03 ... 2.5428389e-03\n",
      "  8.7899331e-05 1.3488175e-03]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oof_predictions = np.zeros((tr.shape[0], Y.shape[1]))\n",
    "\n",
    "y_pred = np.zeros((te.shape[0], 206))\n",
    "for s in SEEDS:\n",
    "\n",
    "    random.seed(s)\n",
    "    np.random.seed(s)\n",
    "    tf.random.set_seed(s)\n",
    "\n",
    "    k = 0\n",
    "    kf = KFold(n_splits=KFOLDS, shuffle=True, random_state=s)\n",
    "    for train_index, valid_index in kf.split(tr):\n",
    "        file_name = f\"seed{s}_fold{k}\"\n",
    "\n",
    "        print(f\"Inferencing on seed{s} fold{k} ......\")\n",
    "\n",
    "        scaler_1 = load_pickle(model_output_folder, f\"{file_name}_scaler_1\")\n",
    "        pca_gs = load_pickle(model_output_folder, f\"{file_name}_pca_gs\")\n",
    "        pca_cs = load_pickle(model_output_folder, f\"{file_name}_pca_cs\")\n",
    "        X_test_1 = preprocessor_1(te, s, scaler_1, pca_gs, pca_cs)\n",
    "\n",
    "        scaler_2 = load_pickle(model_output_folder, f\"{file_name}_scaler_2\")\n",
    "        X_test_2, scaler_2 = preprocessor_2(second_Xtest, scaler_2)\n",
    "\n",
    "        y_valid_1 = Y[valid_index, :]\n",
    "        y_valid_2 = Y0[valid_index, :]\n",
    "\n",
    "        n_features = X_test_1.shape[1]\n",
    "        n_features_2 = X_test_2.shape[1]\n",
    "\n",
    "        # Model Definition #\n",
    "\n",
    "        input1_ = layers.Input(shape=(n_features, ))\n",
    "        input2_ = layers.Input(shape=(n_features_2, ))\n",
    "\n",
    "        output1 = Sequential([\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(0.2),\n",
    "            layers.Dense(512, activation=\"elu\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(256, activation=\"elu\")\n",
    "        ])(input1_)\n",
    "\n",
    "        answer1 = Sequential([\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(512, \"relu\")\n",
    "        ])(layers.Concatenate()([output1, input2_]))\n",
    "\n",
    "        answer2 = Sequential([\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(512, \"elu\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(256, \"relu\")\n",
    "        ])(layers.Concatenate()([output1, input2_, answer1]))\n",
    "\n",
    "        answer3 = Sequential(\n",
    "            [layers.BatchNormalization(),\n",
    "             layers.Dense(256,\n",
    "                          \"elu\")])(layers.Concatenate()([answer1, answer2]))\n",
    "\n",
    "        answer3_ = Sequential([\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(256, \"relu\")\n",
    "        ])(layers.Concatenate()([answer1, answer2, answer3]))\n",
    "\n",
    "        answer4 = Sequential([\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(\n",
    "                256,\n",
    "                kernel_initializer=tf.keras.initializers.lecun_normal(seed=s),\n",
    "                activation='selu',\n",
    "                name='last_frozen'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(\n",
    "                206,\n",
    "                kernel_initializer=tf.keras.initializers.lecun_normal(seed=s),\n",
    "                activation='selu')\n",
    "        ])(layers.Concatenate()([output1, answer2, answer3, answer3_]))\n",
    "\n",
    "        # Scored Training #\n",
    "\n",
    "        answer5 = Sequential(\n",
    "            [layers.BatchNormalization(),\n",
    "             layers.Dense(Y.shape[1], \"sigmoid\")])(answer4)\n",
    "\n",
    "        m_nn = tf.keras.Model([input1_, input2_], answer5)\n",
    "\n",
    "        m_nn.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "                     loss=losses.BinaryCrossentropy(\n",
    "                         label_smoothing=label_smoothing_alpha),\n",
    "                     metrics=logloss)\n",
    "\n",
    "        # Load final model\n",
    "        m_nn = tf.keras.models.load_model(\n",
    "            f'{model_output_folder}/{file_name}_final.h5',\n",
    "            custom_objects={'logloss': logloss})\n",
    "\n",
    "        # Generate Submission Prediction #\n",
    "        fold_submit_preds = m_nn.predict([X_test_1, X_test_2],\n",
    "                                         batch_size=batch_size)\n",
    "        y_pred += fold_submit_preds / (KFOLDS * len(SEEDS))\n",
    "        print(fold_submit_preds[:5, :])\n",
    "\n",
    "        k += 1\n",
    "\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T08:46:27.991646Z",
     "iopub.status.busy": "2020-11-11T08:46:27.990901Z",
     "iopub.status.idle": "2020-11-11T08:46:28.000205Z",
     "shell.execute_reply": "2020-11-11T08:46:28.002353Z"
    },
    "papermill": {
     "duration": 14.092036,
     "end_time": "2020-11-11T08:46:28.002567",
     "exception": false,
     "start_time": "2020-11-11T08:46:13.910531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF Validation Loss: 0.015886\n"
     ]
    }
   ],
   "source": [
    "oof_predictions = glob.glob(f'{model_output_folder}/oof_*.npy')[0]\n",
    "oof_predictions = np.load(oof_predictions)\n",
    "\n",
    "oof_loss = mean_logloss(oof_predictions, Y)\n",
    "print(f\"OOF Validation Loss: {oof_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 13.933663,
     "end_time": "2020-11-11T08:46:56.745720",
     "exception": false,
     "start_time": "2020-11-11T08:46:42.812057",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T08:48:54.311631Z",
     "iopub.status.busy": "2020-11-11T08:48:54.310535Z",
     "iopub.status.idle": "2020-11-11T08:48:54.916705Z",
     "shell.execute_reply": "2020-11-11T08:48:54.916073Z"
    },
    "papermill": {
     "duration": 14.67484,
     "end_time": "2020-11-11T08:48:54.916824",
     "exception": false,
     "start_time": "2020-11-11T08:48:40.241984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub.iloc[:, 1:] = y_pred\n",
    "# sub.iloc[:, 1:] = np.clip(y_pred, P_MIN, P_MAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T08:49:24.916192Z",
     "iopub.status.busy": "2020-11-11T08:49:24.915133Z",
     "iopub.status.idle": "2020-11-11T08:49:24.955202Z",
     "shell.execute_reply": "2020-11-11T08:49:24.955799Z"
    },
    "papermill": {
     "duration": 14.848436,
     "end_time": "2020-11-11T08:49:24.955970",
     "exception": false,
     "start_time": "2020-11-11T08:49:10.107534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0004d9e33</td>\n",
       "      <td>0.001296</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.001935</td>\n",
       "      <td>0.019420</td>\n",
       "      <td>0.020473</td>\n",
       "      <td>0.004704</td>\n",
       "      <td>0.003269</td>\n",
       "      <td>0.006187</td>\n",
       "      <td>0.000673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001393</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>0.003299</td>\n",
       "      <td>0.001768</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.001069</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.002398</td>\n",
       "      <td>0.004096</td>\n",
       "      <td>0.002212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_001897cda</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.001519</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.001716</td>\n",
       "      <td>0.004684</td>\n",
       "      <td>0.010775</td>\n",
       "      <td>0.022973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>0.002542</td>\n",
       "      <td>0.002806</td>\n",
       "      <td>0.001027</td>\n",
       "      <td>0.007790</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.002594</td>\n",
       "      <td>0.001286</td>\n",
       "      <td>0.007403</td>\n",
       "      <td>0.003014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_002429b5b</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.022167</td>\n",
       "      <td>0.042731</td>\n",
       "      <td>0.003832</td>\n",
       "      <td>0.005513</td>\n",
       "      <td>0.004710</td>\n",
       "      <td>0.000989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001805</td>\n",
       "      <td>0.001317</td>\n",
       "      <td>0.004991</td>\n",
       "      <td>0.004447</td>\n",
       "      <td>0.003487</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>0.002634</td>\n",
       "      <td>0.005157</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.004254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00276f245</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>0.001318</td>\n",
       "      <td>0.002660</td>\n",
       "      <td>0.016942</td>\n",
       "      <td>0.011872</td>\n",
       "      <td>0.004862</td>\n",
       "      <td>0.002630</td>\n",
       "      <td>0.004053</td>\n",
       "      <td>0.001070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.001678</td>\n",
       "      <td>0.003104</td>\n",
       "      <td>0.016909</td>\n",
       "      <td>0.011048</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>0.002721</td>\n",
       "      <td>0.002255</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>0.003410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_0027f1083</td>\n",
       "      <td>0.001573</td>\n",
       "      <td>0.001310</td>\n",
       "      <td>0.002372</td>\n",
       "      <td>0.013725</td>\n",
       "      <td>0.017782</td>\n",
       "      <td>0.003375</td>\n",
       "      <td>0.006460</td>\n",
       "      <td>0.001758</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>0.003667</td>\n",
       "      <td>0.002335</td>\n",
       "      <td>0.001016</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>0.002159</td>\n",
       "      <td>0.002158</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.001542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>id_ff7004b87</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.001604</td>\n",
       "      <td>0.001575</td>\n",
       "      <td>0.003932</td>\n",
       "      <td>0.004258</td>\n",
       "      <td>0.001658</td>\n",
       "      <td>0.001161</td>\n",
       "      <td>0.004470</td>\n",
       "      <td>0.001559</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001198</td>\n",
       "      <td>0.005512</td>\n",
       "      <td>0.002485</td>\n",
       "      <td>0.188303</td>\n",
       "      <td>0.008189</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.004673</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>0.002685</td>\n",
       "      <td>0.001732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>id_ff925dd0d</td>\n",
       "      <td>0.004433</td>\n",
       "      <td>0.003341</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>0.006062</td>\n",
       "      <td>0.024969</td>\n",
       "      <td>0.005391</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.003098</td>\n",
       "      <td>0.000985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>0.001094</td>\n",
       "      <td>0.002212</td>\n",
       "      <td>0.002787</td>\n",
       "      <td>0.001303</td>\n",
       "      <td>0.001479</td>\n",
       "      <td>0.002179</td>\n",
       "      <td>0.001565</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.001460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3979</th>\n",
       "      <td>id_ffb710450</td>\n",
       "      <td>0.001691</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>0.001161</td>\n",
       "      <td>0.009116</td>\n",
       "      <td>0.039435</td>\n",
       "      <td>0.005469</td>\n",
       "      <td>0.003519</td>\n",
       "      <td>0.003358</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>0.000836</td>\n",
       "      <td>0.001756</td>\n",
       "      <td>0.002104</td>\n",
       "      <td>0.001223</td>\n",
       "      <td>0.000862</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0.001473</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.001430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>id_ffbb869f2</td>\n",
       "      <td>0.001530</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.020892</td>\n",
       "      <td>0.029953</td>\n",
       "      <td>0.006217</td>\n",
       "      <td>0.004849</td>\n",
       "      <td>0.002568</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.001691</td>\n",
       "      <td>0.001306</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.001247</td>\n",
       "      <td>0.001579</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0.002381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3981</th>\n",
       "      <td>id_ffd5800b6</td>\n",
       "      <td>0.001051</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>0.001609</td>\n",
       "      <td>0.013896</td>\n",
       "      <td>0.015367</td>\n",
       "      <td>0.004676</td>\n",
       "      <td>0.003008</td>\n",
       "      <td>0.006680</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.001410</td>\n",
       "      <td>0.002175</td>\n",
       "      <td>0.002868</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>0.001717</td>\n",
       "      <td>0.001262</td>\n",
       "      <td>0.001466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3982 rows Ã— 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
       "0     id_0004d9e33                     0.001296                0.001144   \n",
       "1     id_001897cda                     0.000775                0.001519   \n",
       "2     id_002429b5b                     0.001044                0.000852   \n",
       "3     id_00276f245                     0.001252                0.001318   \n",
       "4     id_0027f1083                     0.001573                0.001310   \n",
       "...            ...                          ...                     ...   \n",
       "3977  id_ff7004b87                     0.001133                0.001604   \n",
       "3978  id_ff925dd0d                     0.004433                0.003341   \n",
       "3979  id_ffb710450                     0.001691                0.001066   \n",
       "3980  id_ffbb869f2                     0.001530                0.001476   \n",
       "3981  id_ffd5800b6                     0.001051                0.001211   \n",
       "\n",
       "      acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
       "0           0.001935                        0.019420   \n",
       "1           0.001309                        0.002160   \n",
       "2           0.003124                        0.022167   \n",
       "3           0.002660                        0.016942   \n",
       "4           0.002372                        0.013725   \n",
       "...              ...                             ...   \n",
       "3977        0.001575                        0.003932   \n",
       "3978        0.001028                        0.006062   \n",
       "3979        0.001161                        0.009116   \n",
       "3980        0.001282                        0.020892   \n",
       "3981        0.001609                        0.013896   \n",
       "\n",
       "      acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n",
       "0                              0.020473                        0.004704   \n",
       "1                              0.001042                        0.001716   \n",
       "2                              0.042731                        0.003832   \n",
       "3                              0.011872                        0.004862   \n",
       "4                              0.017782                        0.003375   \n",
       "...                                 ...                             ...   \n",
       "3977                           0.004258                        0.001658   \n",
       "3978                           0.024969                        0.005391   \n",
       "3979                           0.039435                        0.005469   \n",
       "3980                           0.029953                        0.006217   \n",
       "3981                           0.015367                        0.004676   \n",
       "\n",
       "      adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n",
       "0                       0.003269                       0.006187   \n",
       "1                       0.004684                       0.010775   \n",
       "2                       0.005513                       0.004710   \n",
       "3                       0.002630                       0.004053   \n",
       "4                       0.006460                       0.001758   \n",
       "...                          ...                            ...   \n",
       "3977                    0.001161                       0.004470   \n",
       "3978                    0.004477                       0.003098   \n",
       "3979                    0.003519                       0.003358   \n",
       "3980                    0.004849                       0.002568   \n",
       "3981                    0.003008                       0.006680   \n",
       "\n",
       "      adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                       0.000673  ...                               0.001393   \n",
       "1                       0.022973  ...                               0.001309   \n",
       "2                       0.000989  ...                               0.001805   \n",
       "3                       0.001070  ...                               0.001236   \n",
       "4                       0.000792  ...                               0.001204   \n",
       "...                          ...  ...                                    ...   \n",
       "3977                    0.001559  ...                               0.001198   \n",
       "3978                    0.000985  ...                               0.000838   \n",
       "3979                    0.000531  ...                               0.000731   \n",
       "3980                    0.000717  ...                               0.000683   \n",
       "3981                    0.000516  ...                               0.000870   \n",
       "\n",
       "      trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0         0.001220         0.003299           0.001768   \n",
       "1         0.002542         0.002806           0.001027   \n",
       "2         0.001317         0.004991           0.004447   \n",
       "3         0.001678         0.003104           0.016909   \n",
       "4         0.000916         0.003667           0.002335   \n",
       "...            ...              ...                ...   \n",
       "3977      0.005512         0.002485           0.188303   \n",
       "3978      0.001094         0.002212           0.002787   \n",
       "3979      0.000836         0.001756           0.002104   \n",
       "3980      0.000558         0.002887           0.001691   \n",
       "3981      0.001410         0.002175           0.002868   \n",
       "\n",
       "      tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                      0.000743                               0.001069   \n",
       "1                      0.007790                               0.001193   \n",
       "2                      0.003487                               0.001143   \n",
       "3                      0.011048                               0.001360   \n",
       "4                      0.001016                               0.001098   \n",
       "...                         ...                                    ...   \n",
       "3977                   0.008189                               0.001548   \n",
       "3978                   0.001303                               0.001479   \n",
       "3979                   0.001223                               0.000862   \n",
       "3980                   0.001306                               0.000866   \n",
       "3981                   0.001157                               0.000964   \n",
       "\n",
       "      vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0            0.002160   0.002398                    0.004096       0.002212  \n",
       "1            0.002594   0.001286                    0.007403       0.003014  \n",
       "2            0.002634   0.005157                    0.002930       0.004254  \n",
       "3            0.002721   0.002255                    0.002252       0.003410  \n",
       "4            0.002159   0.002158                    0.000675       0.001542  \n",
       "...               ...        ...                         ...            ...  \n",
       "3977         0.004673   0.001353                    0.002685       0.001732  \n",
       "3978         0.002179   0.001565                    0.000748       0.001460  \n",
       "3979         0.000872   0.001473                    0.000705       0.001430  \n",
       "3980         0.001247   0.001579                    0.000872       0.002381  \n",
       "3981         0.001277   0.001717                    0.001262       0.001466  \n",
       "\n",
       "[3982 rows x 207 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T08:50:23.604717Z",
     "iopub.status.busy": "2020-11-11T08:50:23.601559Z",
     "iopub.status.idle": "2020-11-11T08:50:26.002857Z",
     "shell.execute_reply": "2020-11-11T08:50:26.001634Z"
    },
    "papermill": {
     "duration": 16.925683,
     "end_time": "2020-11-11T08:50:26.003039",
     "exception": false,
     "start_time": "2020-11-11T08:50:09.077356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set ctl_vehicle to 0\n",
    "sub.iloc[test_features['cp_type'] == 'ctl_vehicle', 1:] = 0\n",
    "\n",
    "# Save Submission\n",
    "sub.to_csv('submission_2heads-looper-super-puper.csv', index=False)\n",
    "# sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T08:50:54.604220Z",
     "iopub.status.busy": "2020-11-11T08:50:54.602918Z",
     "iopub.status.idle": "2020-11-11T08:50:54.644669Z",
     "shell.execute_reply": "2020-11-11T08:50:54.645356Z"
    },
    "papermill": {
     "duration": 14.756009,
     "end_time": "2020-11-11T08:50:54.645529",
     "exception": false,
     "start_time": "2020-11-11T08:50:39.889520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0004d9e33</td>\n",
       "      <td>0.001296</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.001935</td>\n",
       "      <td>0.019420</td>\n",
       "      <td>0.020473</td>\n",
       "      <td>0.004704</td>\n",
       "      <td>0.003269</td>\n",
       "      <td>0.006187</td>\n",
       "      <td>0.000673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001393</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>0.003299</td>\n",
       "      <td>0.001768</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.001069</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.002398</td>\n",
       "      <td>0.004096</td>\n",
       "      <td>0.002212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_001897cda</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.001519</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.001716</td>\n",
       "      <td>0.004684</td>\n",
       "      <td>0.010775</td>\n",
       "      <td>0.022973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>0.002542</td>\n",
       "      <td>0.002806</td>\n",
       "      <td>0.001027</td>\n",
       "      <td>0.007790</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.002594</td>\n",
       "      <td>0.001286</td>\n",
       "      <td>0.007403</td>\n",
       "      <td>0.003014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_002429b5b</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00276f245</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>0.001318</td>\n",
       "      <td>0.002660</td>\n",
       "      <td>0.016942</td>\n",
       "      <td>0.011872</td>\n",
       "      <td>0.004862</td>\n",
       "      <td>0.002630</td>\n",
       "      <td>0.004053</td>\n",
       "      <td>0.001070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.001678</td>\n",
       "      <td>0.003104</td>\n",
       "      <td>0.016909</td>\n",
       "      <td>0.011048</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>0.002721</td>\n",
       "      <td>0.002255</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>0.003410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_0027f1083</td>\n",
       "      <td>0.001573</td>\n",
       "      <td>0.001310</td>\n",
       "      <td>0.002372</td>\n",
       "      <td>0.013725</td>\n",
       "      <td>0.017782</td>\n",
       "      <td>0.003375</td>\n",
       "      <td>0.006460</td>\n",
       "      <td>0.001758</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>0.003667</td>\n",
       "      <td>0.002335</td>\n",
       "      <td>0.001016</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>0.002159</td>\n",
       "      <td>0.002158</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.001542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>id_ff7004b87</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.001604</td>\n",
       "      <td>0.001575</td>\n",
       "      <td>0.003932</td>\n",
       "      <td>0.004258</td>\n",
       "      <td>0.001658</td>\n",
       "      <td>0.001161</td>\n",
       "      <td>0.004470</td>\n",
       "      <td>0.001559</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001198</td>\n",
       "      <td>0.005512</td>\n",
       "      <td>0.002485</td>\n",
       "      <td>0.188303</td>\n",
       "      <td>0.008189</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.004673</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>0.002685</td>\n",
       "      <td>0.001732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>id_ff925dd0d</td>\n",
       "      <td>0.004433</td>\n",
       "      <td>0.003341</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>0.006062</td>\n",
       "      <td>0.024969</td>\n",
       "      <td>0.005391</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.003098</td>\n",
       "      <td>0.000985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>0.001094</td>\n",
       "      <td>0.002212</td>\n",
       "      <td>0.002787</td>\n",
       "      <td>0.001303</td>\n",
       "      <td>0.001479</td>\n",
       "      <td>0.002179</td>\n",
       "      <td>0.001565</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.001460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3979</th>\n",
       "      <td>id_ffb710450</td>\n",
       "      <td>0.001691</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>0.001161</td>\n",
       "      <td>0.009116</td>\n",
       "      <td>0.039435</td>\n",
       "      <td>0.005469</td>\n",
       "      <td>0.003519</td>\n",
       "      <td>0.003358</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>0.000836</td>\n",
       "      <td>0.001756</td>\n",
       "      <td>0.002104</td>\n",
       "      <td>0.001223</td>\n",
       "      <td>0.000862</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0.001473</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.001430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>id_ffbb869f2</td>\n",
       "      <td>0.001530</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.020892</td>\n",
       "      <td>0.029953</td>\n",
       "      <td>0.006217</td>\n",
       "      <td>0.004849</td>\n",
       "      <td>0.002568</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.001691</td>\n",
       "      <td>0.001306</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.001247</td>\n",
       "      <td>0.001579</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0.002381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3981</th>\n",
       "      <td>id_ffd5800b6</td>\n",
       "      <td>0.001051</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>0.001609</td>\n",
       "      <td>0.013896</td>\n",
       "      <td>0.015367</td>\n",
       "      <td>0.004676</td>\n",
       "      <td>0.003008</td>\n",
       "      <td>0.006680</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.001410</td>\n",
       "      <td>0.002175</td>\n",
       "      <td>0.002868</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>0.001717</td>\n",
       "      <td>0.001262</td>\n",
       "      <td>0.001466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3982 rows Ã— 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
       "0     id_0004d9e33                     0.001296                0.001144   \n",
       "1     id_001897cda                     0.000775                0.001519   \n",
       "2     id_002429b5b                     0.000000                0.000000   \n",
       "3     id_00276f245                     0.001252                0.001318   \n",
       "4     id_0027f1083                     0.001573                0.001310   \n",
       "...            ...                          ...                     ...   \n",
       "3977  id_ff7004b87                     0.001133                0.001604   \n",
       "3978  id_ff925dd0d                     0.004433                0.003341   \n",
       "3979  id_ffb710450                     0.001691                0.001066   \n",
       "3980  id_ffbb869f2                     0.001530                0.001476   \n",
       "3981  id_ffd5800b6                     0.001051                0.001211   \n",
       "\n",
       "      acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
       "0           0.001935                        0.019420   \n",
       "1           0.001309                        0.002160   \n",
       "2           0.000000                        0.000000   \n",
       "3           0.002660                        0.016942   \n",
       "4           0.002372                        0.013725   \n",
       "...              ...                             ...   \n",
       "3977        0.001575                        0.003932   \n",
       "3978        0.001028                        0.006062   \n",
       "3979        0.001161                        0.009116   \n",
       "3980        0.001282                        0.020892   \n",
       "3981        0.001609                        0.013896   \n",
       "\n",
       "      acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n",
       "0                              0.020473                        0.004704   \n",
       "1                              0.001042                        0.001716   \n",
       "2                              0.000000                        0.000000   \n",
       "3                              0.011872                        0.004862   \n",
       "4                              0.017782                        0.003375   \n",
       "...                                 ...                             ...   \n",
       "3977                           0.004258                        0.001658   \n",
       "3978                           0.024969                        0.005391   \n",
       "3979                           0.039435                        0.005469   \n",
       "3980                           0.029953                        0.006217   \n",
       "3981                           0.015367                        0.004676   \n",
       "\n",
       "      adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n",
       "0                       0.003269                       0.006187   \n",
       "1                       0.004684                       0.010775   \n",
       "2                       0.000000                       0.000000   \n",
       "3                       0.002630                       0.004053   \n",
       "4                       0.006460                       0.001758   \n",
       "...                          ...                            ...   \n",
       "3977                    0.001161                       0.004470   \n",
       "3978                    0.004477                       0.003098   \n",
       "3979                    0.003519                       0.003358   \n",
       "3980                    0.004849                       0.002568   \n",
       "3981                    0.003008                       0.006680   \n",
       "\n",
       "      adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                       0.000673  ...                               0.001393   \n",
       "1                       0.022973  ...                               0.001309   \n",
       "2                       0.000000  ...                               0.000000   \n",
       "3                       0.001070  ...                               0.001236   \n",
       "4                       0.000792  ...                               0.001204   \n",
       "...                          ...  ...                                    ...   \n",
       "3977                    0.001559  ...                               0.001198   \n",
       "3978                    0.000985  ...                               0.000838   \n",
       "3979                    0.000531  ...                               0.000731   \n",
       "3980                    0.000717  ...                               0.000683   \n",
       "3981                    0.000516  ...                               0.000870   \n",
       "\n",
       "      trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0         0.001220         0.003299           0.001768   \n",
       "1         0.002542         0.002806           0.001027   \n",
       "2         0.000000         0.000000           0.000000   \n",
       "3         0.001678         0.003104           0.016909   \n",
       "4         0.000916         0.003667           0.002335   \n",
       "...            ...              ...                ...   \n",
       "3977      0.005512         0.002485           0.188303   \n",
       "3978      0.001094         0.002212           0.002787   \n",
       "3979      0.000836         0.001756           0.002104   \n",
       "3980      0.000558         0.002887           0.001691   \n",
       "3981      0.001410         0.002175           0.002868   \n",
       "\n",
       "      tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                      0.000743                               0.001069   \n",
       "1                      0.007790                               0.001193   \n",
       "2                      0.000000                               0.000000   \n",
       "3                      0.011048                               0.001360   \n",
       "4                      0.001016                               0.001098   \n",
       "...                         ...                                    ...   \n",
       "3977                   0.008189                               0.001548   \n",
       "3978                   0.001303                               0.001479   \n",
       "3979                   0.001223                               0.000862   \n",
       "3980                   0.001306                               0.000866   \n",
       "3981                   0.001157                               0.000964   \n",
       "\n",
       "      vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0            0.002160   0.002398                    0.004096       0.002212  \n",
       "1            0.002594   0.001286                    0.007403       0.003014  \n",
       "2            0.000000   0.000000                    0.000000       0.000000  \n",
       "3            0.002721   0.002255                    0.002252       0.003410  \n",
       "4            0.002159   0.002158                    0.000675       0.001542  \n",
       "...               ...        ...                         ...            ...  \n",
       "3977         0.004673   0.001353                    0.002685       0.001732  \n",
       "3978         0.002179   0.001565                    0.000748       0.001460  \n",
       "3979         0.000872   0.001473                    0.000705       0.001430  \n",
       "3980         0.001247   0.001579                    0.000872       0.002381  \n",
       "3981         0.001277   0.001717                    0.001262       0.001466  \n",
       "\n",
       "[3982 rows x 207 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "papermill": {
   "duration": 3964.293061,
   "end_time": "2020-11-11T08:51:10.704042",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-11T07:45:06.410981",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
