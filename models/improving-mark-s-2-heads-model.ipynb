{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# Reference:\n# https://www.kaggle.com/demetrypascal/fork-of-2heads-looper-super-puper-plate/notebook\n\nkernel_mode = True","execution_count":6,"outputs":[]},{"metadata":{"papermill":{"duration":0.032594,"end_time":"2020-11-11T07:45:11.484416","exception":false,"start_time":"2020-11-11T07:45:11.451822","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Preparations"},{"metadata":{"papermill":{"duration":0.032435,"end_time":"2020-11-11T07:45:11.549966","exception":false,"start_time":"2020-11-11T07:45:11.517531","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Letâ€™s load the packages and provide some constants for our script:"},{"metadata":{"execution":{"iopub.execute_input":"2020-11-11T07:45:11.624887Z","iopub.status.busy":"2020-11-11T07:45:11.623973Z","iopub.status.idle":"2020-11-11T07:45:18.923587Z","shell.execute_reply":"2020-11-11T07:45:18.922330Z"},"papermill":{"duration":7.340999,"end_time":"2020-11-11T07:45:18.923723","exception":false,"start_time":"2020-11-11T07:45:11.582724","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import KFold\nfrom sklearn import preprocessing\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.decomposition import PCA\nfrom tensorflow.keras import layers, regularizers, Sequential, Model, backend, callbacks, optimizers, metrics, losses\nimport tensorflow as tf\nimport sys\nimport os\nimport random\nimport json\nsys.path.append('../input/iterativestratification')\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\nimport pickle\nfrom pickle import dump, load\nimport glob\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":10,"outputs":[]},{"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2020-11-11T07:45:19.006735Z","iopub.status.busy":"2020-11-11T07:45:19.004625Z","iopub.status.idle":"2020-11-11T07:45:19.007534Z","shell.execute_reply":"2020-11-11T07:45:19.008095Z"},"papermill":{"duration":0.050102,"end_time":"2020-11-11T07:45:19.008235","exception":false,"start_time":"2020-11-11T07:45:18.958133","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"PATH = \"../input/lish-moa\" if kernel_mode else \"/workspace/Kaggle/MoA\"\nmodel_output_folder = \".\" if kernel_mode else f\"{PATH}/2heads-looper-super-puper\"\nos.makedirs(model_output_folder, exist_ok=True)\n\n# SEEDS = [23]\nSEEDS = [23, 228, 1488, 1998, 2208, 2077, 404]\nKFOLDS = 10\n\nlabel_smoothing_alpha = 0.0005\n\nP_MIN = label_smoothing_alpha\nP_MAX = 1 - P_MIN","execution_count":11,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-11T07:45:19.086097Z","iopub.status.busy":"2020-11-11T07:45:19.084976Z","iopub.status.idle":"2020-11-11T07:45:25.522055Z","shell.execute_reply":"2020-11-11T07:45:25.518386Z"},"papermill":{"duration":6.480782,"end_time":"2020-11-11T07:45:25.522253","exception":false,"start_time":"2020-11-11T07:45:19.041471","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Import train data, drop sig_id, cp_type\ntrain_features = pd.read_csv(f'{PATH}/train_features.csv')\n\nnon_ctl_idx = train_features.loc[\n    train_features['cp_type'] != 'ctl_vehicle'].index.to_list()\n\n# Drop training data with ctl vehicle\ntr = train_features.iloc[non_ctl_idx, :].reset_index(drop=True)\n\ntest_features = pd.read_csv(f'{PATH}/test_features.csv')\nte = test_features.copy()","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_targets_scored = pd.read_csv(f'{PATH}/train_targets_scored.csv')\nY = train_targets_scored.drop('sig_id', axis=1)\nY = Y.iloc[non_ctl_idx, :].copy().reset_index(drop=True).values\n\ntrain_targets_nonscored = pd.read_csv(f'{PATH}/train_targets_nonscored.csv')\nY0 = train_targets_nonscored.drop('sig_id', axis=1)\nY0 = Y0.iloc[non_ctl_idx, :].copy().reset_index(drop=True).values\n\nsub = pd.read_csv(f'{PATH}/sample_submission.csv')\nsub.iloc[:, 1:] = 0","execution_count":13,"outputs":[]},{"metadata":{"papermill":{"duration":0.03583,"end_time":"2020-11-11T07:45:28.303012","exception":false,"start_time":"2020-11-11T07:45:28.267182","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Features from t.test"},{"metadata":{"papermill":{"duration":0.036472,"end_time":"2020-11-11T07:45:28.375902","exception":false,"start_time":"2020-11-11T07:45:28.339430","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Here I am getting most important predictors"},{"metadata":{"execution":{"iopub.execute_input":"2020-11-11T07:45:28.455017Z","iopub.status.busy":"2020-11-11T07:45:28.454184Z","iopub.status.idle":"2020-11-11T07:45:28.461483Z","shell.execute_reply":"2020-11-11T07:45:28.460844Z"},"papermill":{"duration":0.049565,"end_time":"2020-11-11T07:45:28.461601","exception":false,"start_time":"2020-11-11T07:45:28.412036","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Import predictors from public kernel\njson_file_path = '../input/t-test-pca-rfe-logistic-regression/main_predictors.json' if kernel_mode \\\n    else \"/workspace/Kaggle/MoA/t-test-pca-rfe-logistic-regression/main_predictors.json\"\n\nwith open(json_file_path, 'r') as j:\n    predictors = json.loads(j.read())\n    predictors = predictors['start_predictors']","execution_count":15,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-11T07:45:28.573031Z","iopub.status.busy":"2020-11-11T07:45:28.565161Z","iopub.status.idle":"2020-11-11T07:45:28.576452Z","shell.execute_reply":"2020-11-11T07:45:28.577030Z"},"papermill":{"duration":0.0786,"end_time":"2020-11-11T07:45:28.577177","exception":false,"start_time":"2020-11-11T07:45:28.498577","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"second_Xtrain = tr[predictors].copy().values\n\nsecond_Xtest = te[predictors].copy().values\nsecond_Xtrain.shape","execution_count":16,"outputs":[{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"(21948, 447)"},"metadata":{}}]},{"metadata":{"papermill":{"duration":0.036297,"end_time":"2020-11-11T07:45:28.650577","exception":false,"start_time":"2020-11-11T07:45:28.614280","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Keras model"},{"metadata":{"papermill":{"duration":0.036666,"end_time":"2020-11-11T07:45:28.724069","exception":false,"start_time":"2020-11-11T07:45:28.687403","status":"completed"},"tags":[]},"cell_type":"markdown","source":"I got idea of **label smoothing** from this notebook: https://www.kaggle.com/kailex/moa-transfer-recipe-with-smoothing"},{"metadata":{"execution":{"iopub.execute_input":"2020-11-11T07:45:28.804562Z","iopub.status.busy":"2020-11-11T07:45:28.803696Z","iopub.status.idle":"2020-11-11T07:45:28.808200Z","shell.execute_reply":"2020-11-11T07:45:28.807569Z"},"papermill":{"duration":0.047482,"end_time":"2020-11-11T07:45:28.808311","exception":false,"start_time":"2020-11-11T07:45:28.760829","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def logloss(y_true, y_pred):\n    y_pred = tf.clip_by_value(y_pred, P_MIN, P_MAX)\n    return -backend.mean(y_true * backend.log(y_pred) +\n                         (1 - y_true) * backend.log(1 - y_pred))","execution_count":17,"outputs":[]},{"metadata":{"papermill":{"duration":0.036797,"end_time":"2020-11-11T07:45:28.956193","exception":false,"start_time":"2020-11-11T07:45:28.919396","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"numeric_features = [c for c in train_features.columns if c != \"sig_id\"]\ngene_experssion_features = [c for c in numeric_features if c.startswith(\"g-\")]\ncell_viability_features = [c for c in numeric_features if c.startswith(\"c-\")]\nlen(gene_experssion_features), len(cell_viability_features)","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"(772, 100)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr = tr.drop(['sig_id', 'cp_type', 'cp_time', 'cp_dose'], axis=1)\nte = test_features.drop(['sig_id', 'cp_type', 'cp_time', 'cp_dose'], axis=1)","execution_count":19,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-11T07:45:29.048267Z","iopub.status.busy":"2020-11-11T07:45:29.046389Z","iopub.status.idle":"2020-11-11T07:45:29.049041Z","shell.execute_reply":"2020-11-11T07:45:29.049614Z"},"papermill":{"duration":0.056399,"end_time":"2020-11-11T07:45:29.049751","exception":false,"start_time":"2020-11-11T07:45:28.993352","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def preprocessor_1(train, valid, test, seed):\n    n_gs = 50\n    n_cs = 50\n\n    # g-mean, c-mean\n    train_g_mean = train[gene_experssion_features].mean(axis=1)\n    valid_g_mean = valid[gene_experssion_features].mean(axis=1)\n    test_g_mean = test[gene_experssion_features].mean(axis=1)\n\n    train_c_mean = train[cell_viability_features].mean(axis=1)\n    valid_c_mean = valid[cell_viability_features].mean(axis=1)\n    test_c_mean = test[cell_viability_features].mean(axis=1)\n\n    train_columns = train.columns.tolist()\n    test_columns = test.columns.tolist()\n\n    train = np.concatenate(\n        (train, train_g_mean[:, np.newaxis], train_c_mean[:, np.newaxis]),\n        axis=1)\n    valid = np.concatenate(\n        (valid, valid_g_mean[:, np.newaxis], valid_c_mean[:, np.newaxis]),\n        axis=1)\n    test = np.concatenate(\n        (test, test_g_mean[:, np.newaxis], test_c_mean[:, np.newaxis]), axis=1)\n\n    # Standard Scaler for Numerical Values\n    scaler = preprocessing.StandardScaler()\n    train = pd.DataFrame(data=scaler.fit_transform(train),\n                         columns=train_columns + [\"g_mean\", \"c_mean\"])\n    valid = pd.DataFrame(data=scaler.transform(valid),\n                         columns=train_columns + [\"g_mean\", \"c_mean\"])\n    test = pd.DataFrame(data=scaler.transform(test),\n                        columns=test_columns + [\"g_mean\", \"c_mean\"])\n\n    pca_gs = PCA(n_components=n_gs, random_state=seed)\n    train_pca_gs = pca_gs.fit_transform(train[gene_experssion_features].values)\n    valid_pca_gs = pca_gs.transform(valid[gene_experssion_features].values)\n    test_pca_gs = pca_gs.transform(test[gene_experssion_features].values)\n\n    pca_cs = PCA(n_components=n_cs, random_state=seed)\n    train_pca_cs = pca_cs.fit_transform(train[cell_viability_features].values)\n    valid_pca_cs = pca_cs.transform(valid[cell_viability_features].values)\n    test_pca_cs = pca_cs.transform(test[cell_viability_features].values)\n\n    # Append Features\n    train = np.concatenate((train, train_pca_gs, train_pca_cs), axis=1)\n    valid = np.concatenate((valid, valid_pca_gs, valid_pca_cs), axis=1)\n    test = np.concatenate((test, test_pca_gs, test_pca_cs), axis=1)\n\n    return train, valid, test, scaler, pca_gs, pca_cs\n\n\ndef preprocessor_2(train, valid, test):\n    # Standard Scaler for Numerical Values\n    scaler = preprocessing.StandardScaler()\n    train = scaler.fit_transform(train)\n    valid = scaler.transform(valid)\n    test = scaler.transform(test)\n\n    return train, valid, test, scaler\n\n\ndef save_pickle(obj, model_output_folder, name):\n    dump(obj, open(f\"{model_output_folder}/{name}.pkl\", 'wb'),\n         pickle.HIGHEST_PROTOCOL)\n\n\ndef load_pickle(model_output_folder, name):\n    return load(open(f\"{model_output_folder}/{name}.pkl\", 'rb'))\n\n\ndef mean_logloss(y_pred, y_true):\n    logloss = (1 - y_true) * np.log(1 - y_pred +\n                                    1e-15) + y_true * np.log(y_pred + 1e-15)\n    return np.mean(-logloss)","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr.shape, te.shape","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"((21948, 872), (3982, 872))"},"metadata":{}}]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-11T07:45:30.295979Z","iopub.status.busy":"2020-11-11T07:45:30.274930Z","iopub.status.idle":"2020-11-11T08:45:30.221121Z","shell.execute_reply":"2020-11-11T08:45:30.220025Z"},"papermill":{"duration":3600.006513,"end_time":"2020-11-11T08:45:30.221259","exception":false,"start_time":"2020-11-11T07:45:30.214746","status":"completed"},"scrolled":true,"tags":[],"trusted":true},"cell_type":"code","source":"oof_predictions = np.zeros((tr.shape[0], Y.shape[1]))\n\ny_pred = np.zeros((te.shape[0], 206))\nfor s in SEEDS:\n\n    random.seed(s)\n    np.random.seed(s)\n    tf.random.set_seed(s)\n\n    k = 0\n    kf = KFold(n_splits=KFOLDS, shuffle=True, random_state=s)\n    for train_index, valid_index in kf.split(tr):\n        file_name = f\"seed{s}_fold{k}\"\n\n        X_train_1, X_valid_1, X_test_1, scaler_1, pca_gs, pca_cs = preprocessor_1(\n            tr.iloc[train_index, :], tr.iloc[valid_index, :], te, s)\n        save_pickle(scaler_1, model_output_folder, f\"{file_name}_scaler_1\")\n        save_pickle(pca_gs, model_output_folder, f\"{file_name}_pca_gs\")\n        save_pickle(pca_cs, model_output_folder, f\"{file_name}_pca_cs\")\n\n        X_train_2, X_valid_2, X_test_2, scaler_2 = preprocessor_2(\n            second_Xtrain[train_index, :], second_Xtrain[valid_index, :],\n            second_Xtest)\n        save_pickle(scaler_2, model_output_folder, f\"{file_name}_scaler_2\")\n\n        y_train_1, y_valid_1 = Y[train_index, :], Y[valid_index, :]\n        y_train_2, y_valid_2 = Y0[train_index, :], Y0[valid_index, :]\n\n        n_features = X_train_1.shape[1]\n        n_features_2 = X_train_2.shape[1]\n\n        early_stopping = callbacks.EarlyStopping(min_delta=1e-5,\n                                                 monitor='val_loss',\n                                                 patience=10,\n                                                 verbose=0,\n                                                 mode='min',\n                                                 restore_best_weights=True)\n        check_point = callbacks.ModelCheckpoint(\n            f\"{model_output_folder}/{file_name}_nonscore.h5\",\n            save_best_only=True,\n            verbose=0,\n            mode=\"min\")\n        reduce_lr = callbacks.ReduceLROnPlateau(factor=0.5,\n                                                patience=4,\n                                                verbose=0,\n                                                mode=\"auto\")\n\n        # Model Definition #\n\n        input1_ = layers.Input(shape=(n_features, ))\n        input2_ = layers.Input(shape=(n_features_2, ))\n\n        output1 = Sequential([\n            layers.BatchNormalization(),\n            layers.Dropout(0.2),\n            layers.Dense(512, activation=\"elu\"),\n            layers.BatchNormalization(),\n            layers.Dense(256, activation=\"elu\")\n        ])(input1_)\n\n        answer1 = Sequential([\n            layers.BatchNormalization(),\n            layers.Dropout(0.3),\n            layers.Dense(512, \"relu\")\n        ])(layers.Concatenate()([output1, input2_]))\n\n        answer2 = Sequential([\n            layers.BatchNormalization(),\n            layers.Dense(512, \"elu\"),\n            layers.BatchNormalization(),\n            layers.Dense(256, \"relu\")\n        ])(layers.Concatenate()([output1, input2_, answer1]))\n\n        answer3 = Sequential(\n            [layers.BatchNormalization(),\n             layers.Dense(256,\n                          \"elu\")])(layers.Concatenate()([answer1, answer2]))\n\n        answer3_ = Sequential([\n            layers.BatchNormalization(),\n            layers.Dense(256, \"relu\")\n        ])(layers.Concatenate()([answer1, answer2, answer3]))\n\n        answer4 = Sequential([\n            layers.BatchNormalization(),\n            layers.Dense(\n                256,\n                kernel_initializer=tf.keras.initializers.lecun_normal(seed=s),\n                activation='selu',\n                name='last_frozen'),\n            layers.BatchNormalization(),\n            layers.Dense(\n                206,\n                kernel_initializer=tf.keras.initializers.lecun_normal(seed=s),\n                activation='selu')\n        ])(layers.Concatenate()([output1, answer2, answer3, answer3_]))\n\n        # Non-scored Training #\n\n        answer5 = Sequential([\n            layers.BatchNormalization(),\n            layers.Dense(Y0.shape[1], \"sigmoid\")\n        ])(answer4)\n\n        m_nn = tf.keras.Model([input1_, input2_], answer5)\n\n        m_nn.compile(optimizer=optimizers.Adam(learning_rate=0.002),\n                     loss=losses.BinaryCrossentropy(\n                         label_smoothing=label_smoothing_alpha),\n                     metrics=logloss)\n\n        history = m_nn.fit([X_train_1, X_train_2],\n                           y_train_2,\n                           epochs=50,\n                           batch_size=64,\n                           validation_data=([X_valid_1, X_valid_2], y_valid_2),\n                           callbacks=[check_point, early_stopping, reduce_lr],\n                           verbose=0)\n        m_nn = tf.keras.models.load_model(\n            f\"{model_output_folder}/{file_name}_nonscore.h5\",\n            custom_objects={'logloss': logloss})\n\n        valid_metric_old = m_nn.evaluate([X_valid_1, X_valid_2],\n                                         y_valid_2,\n                                         verbose=0)[0]  # loss\n        print('After non-scored training: validation_loss =', valid_metric_old)\n\n        # Scored Training #\n\n        answer5 = Sequential(\n            [layers.BatchNormalization(),\n             layers.Dense(Y.shape[1], \"sigmoid\")])(answer4)\n\n        m_nn = tf.keras.Model([input1_, input2_], answer5)\n\n        m_nn.compile(optimizer=optimizers.Adam(learning_rate=0.002),\n                     loss=losses.BinaryCrossentropy(\n                         label_smoothing=label_smoothing_alpha),\n                     metrics=logloss)\n\n        early_stopping = callbacks.EarlyStopping(min_delta=1e-5,\n                                                 monitor='val_loss',\n                                                 patience=10,\n                                                 verbose=1,\n                                                 mode='min',\n                                                 restore_best_weights=True)\n        check_point = callbacks.ModelCheckpoint(\n            f\"{model_output_folder}/{file_name}.h5\",\n            save_best_only=True,\n            verbose=0,\n            mode=\"min\")\n        reduce_lr = callbacks.ReduceLROnPlateau(factor=0.5,\n                                                patience=4,\n                                                verbose=0,\n                                                mode=\"auto\")\n\n        history = m_nn.fit([X_train_1, X_train_2],\n                           y_train_1,\n                           epochs=50,\n                           batch_size=64,\n                           validation_data=([X_valid_1, X_valid_2], y_valid_1),\n                           callbacks=[check_point, early_stopping, reduce_lr],\n                           verbose=0)\n        m_nn = tf.keras.models.load_model(\n            f\"{model_output_folder}/{file_name}.h5\",\n            custom_objects={'logloss': logloss})\n\n        # val_old = m_nn.predict([X_valid_1, X_valid_2])\n        # valid_metric_old = mean_logloss(val_old, y_valid_1)\n        valid_metric_old = m_nn.evaluate([X_valid_1, X_valid_2],\n                                         y_valid_1,\n                                         verbose=0)[0]  # loss\n        print('After scored training: validation_loss =', valid_metric_old)\n\n        m_nn.save(f'{model_output_folder}/tmp.h5')\n\n        print('Before loop: validation_loss =', valid_metric_old)\n\n        # big loop\n        loop = 1\n        while True:\n\n            # Freeze_weights(m_nn, to = 'last_frozen')\n            for i, layer in enumerate(m_nn.layers):\n                if layer.name == \"last_frozen\":\n                    layer.trainable = True\n                    break\n                else:\n                    layer.trainable = False\n\n            m_nn.compile(optimizer=tf.keras.optimizers.Adadelta(lr=0.001 / 3),\n                         loss=tf.losses.BinaryCrossentropy(\n                             label_smoothing=label_smoothing_alpha),\n                         metrics=logloss)\n\n            # Frozen Mode #\n\n            reps = 0\n            improved = 0\n            patience = 3\n            while True:\n                history = m_nn.fit([X_valid_1, X_valid_2],\n                                   y_valid_1,\n                                   epochs=1,\n                                   batch_size=64,\n                                   verbose=0)\n\n                # val_preds = m_nn.predict([X_valid_1, X_valid_2])\n                # valid_metric = mean_logloss(val_preds, y_valid_1)\n                valid_metric = m_nn.evaluate([X_valid_1, X_valid_2],\n                                             y_valid_1,\n                                             verbose=0)[0]\n\n                if valid_metric_old - valid_metric >= 1e-6:\n                    print('Improved:', valid_metric, 'from', valid_metric_old)\n                    reps += 1\n                    improved += 1\n                    valid_metric_old = valid_metric\n                    m_nn.save(f'{model_output_folder}/tmp.h5')\n                elif reps < patience:\n                    reps += 1\n                    pass\n                else:\n                    print('No Improvement, stopped')\n                    m_nn = tf.keras.models.load_model(\n                        f'{model_output_folder}/tmp.h5',\n                        custom_objects={'logloss': logloss})\n                    print(loop, 'loop ---> After Frozen-step best valid =',\n                          valid_metric_old, 'after', reps, 'epochs \\n')\n\n                    break\n\n            # Should continue training instead?\n            # if (improved == 0):  # no progress? STOP!\n            #     break\n\n            # Unfrozen Mode #\n\n            # Unfreeze all layers\n            for i, layer in enumerate(m_nn.layers):\n                layer.trainable = True\n\n            m_nn.compile(optimizer=tf.keras.optimizers.Adadelta(lr=0.001 / 5),\n                         loss=tf.losses.BinaryCrossentropy(\n                             label_smoothing=label_smoothing_alpha),\n                         metrics=logloss)\n\n            reps = 0\n            improved = 0\n            patience = 3\n            while True:\n                history = m_nn.fit([X_valid_1, X_valid_2],\n                                   y_valid_1,\n                                   epochs=1,\n                                   batch_size=64,\n                                   verbose=0)\n\n                # val_preds = m_nn.predict([X_valid_1, X_valid_2])\n                # valid_metric = mean_logloss(val_preds, y_valid_1)\n                valid_metric = m_nn.evaluate([X_valid_1, X_valid_2],\n                                             y_valid_1,\n                                             verbose=0)[0]\n\n                if valid_metric_old - valid_metric >= 1e-6:\n                    print('Improved:', valid_metric, 'from', valid_metric_old)\n                    reps += 1\n                    improved += 1\n                    valid_metric_old = valid_metric\n                    m_nn.save(f'{model_output_folder}/tmp.h5')\n                elif reps < patience:\n                    reps += 1\n                    pass\n                else:\n                    print('No Improvement, stopped')\n                    m_nn = tf.keras.models.load_model(\n                        f'{model_output_folder}/tmp.h5',\n                        custom_objects={'logloss': logloss})\n                    print(loop, 'loop ---> After Non-frozen-step best valid =',\n                          valid_metric_old, 'after', reps, 'epochs \\n')\n\n                    break\n\n            print(\"Total Non-frozen-step improved:\", improved)\n            if (improved == 0):\n                break\n\n            loop += 1\n\n        # Save Final Model\n        m_nn.save(f'{model_output_folder}/{file_name}_final.h5')\n\n        # OOF Predictions and Score #\n\n        val_preds = m_nn.predict([X_valid_1, X_valid_2])\n        fold_valid_score = mean_logloss(val_preds, y_valid_1)\n\n        oof_predictions[valid_index, :] += val_preds / len(SEEDS)\n        print('\\nSeed:', s, 'Fold:', k, 'score:', fold_valid_score)\n\n        # Generate Submission Prediction #\n        fold_submit_preds = m_nn.predict([X_test_1, X_test_2])\n        y_pred += fold_submit_preds / (KFOLDS * len(SEEDS))\n        print(fold_submit_preds[:5, :])\n\n        k += 1\n\n        print('\\n')","execution_count":22,"outputs":[{"output_type":"stream","text":"After non-scored training: validation_loss = 0.006339543499052525\nRestoring model weights from the end of the best epoch.\nEpoch 00015: early stopping\nAfter scored training: validation_loss = 0.017912790179252625\nBefore loop: validation_loss = 0.017912790179252625\nNo Improvement, stopped\n1 loop ---> After Frozen-step best valid = 0.017912790179252625 after 3 epochs \n\nImproved: 0.017863823100924492 from 0.017912790179252625\nImproved: 0.017837291583418846 from 0.017863823100924492\nImproved: 0.017823895439505577 from 0.017837291583418846\nImproved: 0.017817867919802666 from 0.017823895439505577\nImproved: 0.01781565509736538 from 0.017817867919802666\nImproved: 0.017814435064792633 from 0.01781565509736538\nNo Improvement, stopped\n1 loop ---> After Non-frozen-step best valid = 0.017814435064792633 after 6 epochs \n\nTotal Non-frozen-step improved: 6\nNo Improvement, stopped\n2 loop ---> After Frozen-step best valid = 0.017814435064792633 after 3 epochs \n\nNo Improvement, stopped\n2 loop ---> After Non-frozen-step best valid = 0.017814435064792633 after 3 epochs \n\nTotal Non-frozen-step improved: 0\n\nSeed: 23 Fold: 0 score: 0.016105590742985378\n[[0.00095757 0.00097123 0.00042359 ... 0.00152713 0.0016269  0.00199187]\n [0.00058122 0.00155103 0.00211736 ... 0.00113585 0.00146205 0.00204311]\n [0.00067882 0.00090597 0.00143573 ... 0.00230639 0.00446115 0.00353422]\n [0.00029556 0.00036963 0.00395868 ... 0.00073369 0.00815529 0.00412795]\n [0.00107052 0.00078362 0.00062596 ... 0.00169501 0.00050375 0.00098426]]\n\n\nAfter non-scored training: validation_loss = 0.0060945372097194195\nRestoring model weights from the end of the best epoch.\nEpoch 00017: early stopping\nAfter scored training: validation_loss = 0.018424445763230324\nBefore loop: validation_loss = 0.018424445763230324\nNo Improvement, stopped\n1 loop ---> After Frozen-step best valid = 0.018424445763230324 after 3 epochs \n\nImproved: 0.018401827663183212 from 0.018424445763230324\nImproved: 0.018398435786366463 from 0.018401827663183212\nNo Improvement, stopped\n1 loop ---> After Non-frozen-step best valid = 0.018398435786366463 after 3 epochs \n\nTotal Non-frozen-step improved: 2\nNo Improvement, stopped\n2 loop ---> After Frozen-step best valid = 0.018398435786366463 after 3 epochs \n\nNo Improvement, stopped\n2 loop ---> After Non-frozen-step best valid = 0.018398435786366463 after 3 epochs \n\nTotal Non-frozen-step improved: 0\n\nSeed: 23 Fold: 1 score: 0.016608354458414378\n[[3.5817278e-04 1.3274288e-04 1.4816956e-03 ... 2.4997294e-03\n  7.4364035e-03 9.5422426e-04]\n [1.0220908e-04 1.2254226e-03 4.6965043e-04 ... 2.1694070e-03\n  1.7769260e-02 1.7894197e-03]\n [4.0820808e-04 2.1502444e-04 1.2738124e-03 ... 4.3555466e-03\n  3.0268794e-03 5.2263523e-03]\n [2.7044979e-04 9.4788084e-05 2.1178317e-03 ... 1.7125704e-03\n  2.6884119e-04 3.5242271e-03]\n [5.1515596e-04 2.0832280e-04 1.4903480e-03 ... 8.9486927e-04\n  4.5343937e-04 3.7363925e-04]]\n\n\nAfter non-scored training: validation_loss = 0.005982274655252695\nRestoring model weights from the end of the best epoch.\nEpoch 00016: early stopping\nAfter scored training: validation_loss = 0.018220633268356323\nBefore loop: validation_loss = 0.018220633268356323\nNo Improvement, stopped\n1 loop ---> After Frozen-step best valid = 0.018220633268356323 after 3 epochs \n\nImproved: 0.01820487156510353 from 0.018220633268356323\nImproved: 0.018203459680080414 from 0.01820487156510353\nNo Improvement, stopped\n1 loop ---> After Non-frozen-step best valid = 0.018203459680080414 after 3 epochs \n\nTotal Non-frozen-step improved: 2\nNo Improvement, stopped\n2 loop ---> After Frozen-step best valid = 0.018203459680080414 after 3 epochs \n\nImproved: 0.018202422186732292 from 0.018203459680080414\nNo Improvement, stopped\n2 loop ---> After Non-frozen-step best valid = 0.018202422186732292 after 3 epochs \n\nTotal Non-frozen-step improved: 1\nNo Improvement, stopped\n3 loop ---> After Frozen-step best valid = 0.018202422186732292 after 3 epochs \n\nNo Improvement, stopped\n3 loop ---> After Non-frozen-step best valid = 0.018202422186732292 after 3 epochs \n\nTotal Non-frozen-step improved: 0\n\nSeed: 23 Fold: 2 score: 0.0164531453070544\n[[1.89938233e-04 8.03110306e-04 2.71006045e-03 ... 1.44006091e-03\n  9.38731187e-04 1.33188628e-03]\n [4.79675109e-05 7.91870698e-04 1.37091347e-03 ... 6.32514770e-04\n  1.66121051e-02 1.23136304e-03]\n [1.54316280e-04 6.60007936e-04 3.26987775e-03 ... 1.14147067e-02\n  1.16614215e-02 2.08502845e-03]\n [3.12277436e-04 9.72038135e-04 2.35397415e-03 ... 2.36429879e-03\n  6.88529294e-03 3.65285971e-03]\n [7.50698382e-04 1.54160522e-03 6.73406699e-04 ... 2.38399324e-03\n  3.52972740e-04 4.15046141e-03]]\n\n\nAfter non-scored training: validation_loss = 0.006378560326993465\nRestoring model weights from the end of the best epoch.\nEpoch 00016: early stopping\nAfter scored training: validation_loss = 0.018509123474359512\nBefore loop: validation_loss = 0.018509123474359512\nNo Improvement, stopped\n1 loop ---> After Frozen-step best valid = 0.018509123474359512 after 3 epochs \n\nImproved: 0.018469225615262985 from 0.018509123474359512\nImproved: 0.018454300239682198 from 0.018469225615262985\nImproved: 0.018452346324920654 from 0.018454300239682198\nNo Improvement, stopped\n1 loop ---> After Non-frozen-step best valid = 0.018452346324920654 after 3 epochs \n\nTotal Non-frozen-step improved: 3\nNo Improvement, stopped\n2 loop ---> After Frozen-step best valid = 0.018452346324920654 after 3 epochs \n\nNo Improvement, stopped\n2 loop ---> After Non-frozen-step best valid = 0.018452346324920654 after 3 epochs \n\nTotal Non-frozen-step improved: 0\n\nSeed: 23 Fold: 3 score: 0.01670444825123165\n[[0.00028451 0.00021241 0.00222091 ... 0.00109531 0.00423554 0.00219226]\n [0.00015929 0.0004197  0.00059083 ... 0.00049483 0.00153603 0.00322468]\n [0.00021446 0.00051327 0.00181234 ... 0.00549901 0.00483364 0.00496503]\n [0.00057175 0.00034892 0.00187616 ... 0.00209912 0.00056211 0.00256288]\n [0.0012109  0.0006301  0.0014235  ... 0.00144526 0.00067413 0.00066829]]\n\n\n","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-1ff19c3971f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    116\u001b[0m                            \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_valid_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid_2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                            \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheck_point\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_lr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m                            verbose=0)\n\u001b[0m\u001b[1;32m    119\u001b[0m         m_nn = tf.keras.models.load_model(\n\u001b[1;32m    120\u001b[0m             \u001b[0;34mf\"{model_output_folder}/{file_name}_nonscore.h5\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-11T08:46:27.991646Z","iopub.status.busy":"2020-11-11T08:46:27.990901Z","iopub.status.idle":"2020-11-11T08:46:28.000205Z","shell.execute_reply":"2020-11-11T08:46:28.002353Z"},"papermill":{"duration":14.092036,"end_time":"2020-11-11T08:46:28.002567","exception":false,"start_time":"2020-11-11T08:46:13.910531","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"oof_loss = mean_logloss(oof_predictions, Y)\nprint(f\"OOF Validation Loss: {oof_loss:.6f}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open(f'{model_output_folder}/oof_{oof_loss}.npy', 'wb') as f:\n    np.save(f, oof_predictions)\n\nwith open(f'{model_output_folder}/oof_{oof_loss}.npy', 'rb') as f:\n    tmp = np.load(f)\n    print(tmp.shape)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":13.933663,"end_time":"2020-11-11T08:46:56.745720","exception":false,"start_time":"2020-11-11T08:46:42.812057","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Submission"},{"metadata":{"execution":{"iopub.execute_input":"2020-11-11T08:48:54.311631Z","iopub.status.busy":"2020-11-11T08:48:54.310535Z","iopub.status.idle":"2020-11-11T08:48:54.916705Z","shell.execute_reply":"2020-11-11T08:48:54.916073Z"},"papermill":{"duration":14.67484,"end_time":"2020-11-11T08:48:54.916824","exception":false,"start_time":"2020-11-11T08:48:40.241984","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"sub.iloc[:, 1:] = y_pred\n# sub.iloc[:, 1:] = np.clip(y_pred, P_MIN, P_MAX)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-11T08:49:24.916192Z","iopub.status.busy":"2020-11-11T08:49:24.915133Z","iopub.status.idle":"2020-11-11T08:49:24.955202Z","shell.execute_reply":"2020-11-11T08:49:24.955799Z"},"papermill":{"duration":14.848436,"end_time":"2020-11-11T08:49:24.955970","exception":false,"start_time":"2020-11-11T08:49:10.107534","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"sub","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-11T08:50:23.604717Z","iopub.status.busy":"2020-11-11T08:50:23.601559Z","iopub.status.idle":"2020-11-11T08:50:26.002857Z","shell.execute_reply":"2020-11-11T08:50:26.001634Z"},"papermill":{"duration":16.925683,"end_time":"2020-11-11T08:50:26.003039","exception":false,"start_time":"2020-11-11T08:50:09.077356","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Set ctl_vehicle to 0\nsub.iloc[test_features['cp_type'] == 'ctl_vehicle', 1:] = 0\n\n# Save Submission\nsub.to_csv('submission_2heads-looper-super-puper.csv', index=False)\nsub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-11-11T08:50:54.604220Z","iopub.status.busy":"2020-11-11T08:50:54.602918Z","iopub.status.idle":"2020-11-11T08:50:54.644669Z","shell.execute_reply":"2020-11-11T08:50:54.645356Z"},"papermill":{"duration":14.756009,"end_time":"2020-11-11T08:50:54.645529","exception":false,"start_time":"2020-11-11T08:50:39.889520","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"sub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}