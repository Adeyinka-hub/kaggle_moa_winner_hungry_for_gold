{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference:\n",
    "# https://www.kaggle.com/demetrypascal/fork-of-2heads-looper-super-puper-plate/notebook\n",
    "\n",
    "kernel_mode = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.032594,
     "end_time": "2020-11-11T07:45:11.484416",
     "exception": false,
     "start_time": "2020-11-11T07:45:11.451822",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.032435,
     "end_time": "2020-11-11T07:45:11.549966",
     "exception": false,
     "start_time": "2020-11-11T07:45:11.517531",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Letâ€™s load the packages and provide some constants for our script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T07:45:11.624887Z",
     "iopub.status.busy": "2020-11-11T07:45:11.623973Z",
     "iopub.status.idle": "2020-11-11T07:45:18.923587Z",
     "shell.execute_reply": "2020-11-11T07:45:18.922330Z"
    },
    "papermill": {
     "duration": 7.340999,
     "end_time": "2020-11-11T07:45:18.923723",
     "exception": false,
     "start_time": "2020-11-11T07:45:11.582724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow.keras import layers, regularizers, Sequential, Model, backend, callbacks, optimizers, metrics, losses\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import random\n",
    "import json\n",
    "sys.path.append('../input/iterative-stratification')\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "import pickle\n",
    "from pickle import dump, load\n",
    "import glob\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2020-11-11T07:45:19.006735Z",
     "iopub.status.busy": "2020-11-11T07:45:19.004625Z",
     "iopub.status.idle": "2020-11-11T07:45:19.007534Z",
     "shell.execute_reply": "2020-11-11T07:45:19.008095Z"
    },
    "papermill": {
     "duration": 0.050102,
     "end_time": "2020-11-11T07:45:19.008235",
     "exception": false,
     "start_time": "2020-11-11T07:45:18.958133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "PATH = \"../input/lish-moa\" if kernel_mode else \"/workspace/Kaggle/MoA\"\n",
    "# SEEDS = [23]\n",
    "SEEDS = [23, 228, 1488, 1998, 2208, 2077, 404]\n",
    "KFOLDS = 10\n",
    "\n",
    "label_smoothing_alpha = 0.0005\n",
    "\n",
    "P_MIN = label_smoothing_alpha\n",
    "P_MAX = 1 - P_MIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T07:45:19.086097Z",
     "iopub.status.busy": "2020-11-11T07:45:19.084976Z",
     "iopub.status.idle": "2020-11-11T07:45:25.522055Z",
     "shell.execute_reply": "2020-11-11T07:45:25.518386Z"
    },
    "papermill": {
     "duration": 6.480782,
     "end_time": "2020-11-11T07:45:25.522253",
     "exception": false,
     "start_time": "2020-11-11T07:45:19.041471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import train data, drop sig_id, cp_type\n",
    "train_features = pd.read_csv(f'{PATH}/train_features.csv')\n",
    "\n",
    "non_ctl_idx = train_features.loc[\n",
    "    train_features['cp_type'] != 'ctl_vehicle'].index.to_list()\n",
    "\n",
    "# Drop training data with ctl vehicle\n",
    "tr = train_features.iloc[non_ctl_idx, :].reset_index(drop=True)\n",
    "\n",
    "test_features = pd.read_csv(f'{PATH}/test_features.csv')\n",
    "te = test_features.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets_scored = pd.read_csv(f'{PATH}/train_targets_scored.csv')\n",
    "Y = train_targets_scored.drop('sig_id', axis=1)\n",
    "Y = Y.iloc[non_ctl_idx, :].copy().reset_index(drop=True).values\n",
    "\n",
    "train_targets_nonscored = pd.read_csv(f'{PATH}/train_targets_nonscored.csv')\n",
    "Y0 = train_targets_nonscored.drop('sig_id', axis=1)\n",
    "Y0 = Y0.iloc[non_ctl_idx, :].copy().reset_index(drop=True).values\n",
    "\n",
    "sub = pd.read_csv(f'{PATH}/sample_submission.csv')\n",
    "sub.iloc[:, 1:] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.03583,
     "end_time": "2020-11-11T07:45:28.303012",
     "exception": false,
     "start_time": "2020-11-11T07:45:28.267182",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Features from t.test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.036472,
     "end_time": "2020-11-11T07:45:28.375902",
     "exception": false,
     "start_time": "2020-11-11T07:45:28.339430",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here I am getting most important predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T07:45:28.455017Z",
     "iopub.status.busy": "2020-11-11T07:45:28.454184Z",
     "iopub.status.idle": "2020-11-11T07:45:28.461483Z",
     "shell.execute_reply": "2020-11-11T07:45:28.460844Z"
    },
    "papermill": {
     "duration": 0.049565,
     "end_time": "2020-11-11T07:45:28.461601",
     "exception": false,
     "start_time": "2020-11-11T07:45:28.412036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import predictors from public kernel\n",
    "json_file_path = '../input/t-test-pca-rfe-logistic-regression/main_predictors.json' if kernel_mode \\\n",
    "    else \"/workspace/Kaggle/MoA/t-test-pca-rfe-logistic-regression/main_predictors.json\"\n",
    "\n",
    "with open(json_file_path, 'r') as j:\n",
    "    predictors = json.loads(j.read())\n",
    "    predictors = predictors['start_predictors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T07:45:28.573031Z",
     "iopub.status.busy": "2020-11-11T07:45:28.565161Z",
     "iopub.status.idle": "2020-11-11T07:45:28.576452Z",
     "shell.execute_reply": "2020-11-11T07:45:28.577030Z"
    },
    "papermill": {
     "duration": 0.0786,
     "end_time": "2020-11-11T07:45:28.577177",
     "exception": false,
     "start_time": "2020-11-11T07:45:28.498577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21948, 447)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_Xtrain = tr[predictors].copy().values\n",
    "\n",
    "second_Xtest = te[predictors].copy().values\n",
    "second_Xtrain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.036297,
     "end_time": "2020-11-11T07:45:28.650577",
     "exception": false,
     "start_time": "2020-11-11T07:45:28.614280",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Keras model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.036666,
     "end_time": "2020-11-11T07:45:28.724069",
     "exception": false,
     "start_time": "2020-11-11T07:45:28.687403",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "I got idea of **label smoothing** from this notebook: https://www.kaggle.com/kailex/moa-transfer-recipe-with-smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T07:45:28.804562Z",
     "iopub.status.busy": "2020-11-11T07:45:28.803696Z",
     "iopub.status.idle": "2020-11-11T07:45:28.808200Z",
     "shell.execute_reply": "2020-11-11T07:45:28.807569Z"
    },
    "papermill": {
     "duration": 0.047482,
     "end_time": "2020-11-11T07:45:28.808311",
     "exception": false,
     "start_time": "2020-11-11T07:45:28.760829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def logloss(y_true, y_pred):\n",
    "    y_pred = tf.clip_by_value(y_pred, P_MIN, P_MAX)\n",
    "    return -backend.mean(y_true * backend.log(y_pred) +\n",
    "                         (1 - y_true) * backend.log(1 - y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.036797,
     "end_time": "2020-11-11T07:45:28.956193",
     "exception": false,
     "start_time": "2020-11-11T07:45:28.919396",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(772, 100)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_features = [c for c in train_features.columns if c != \"sig_id\"]\n",
    "gene_experssion_features = [c for c in numeric_features if c.startswith(\"g-\")]\n",
    "cell_viability_features = [c for c in numeric_features if c.startswith(\"c-\")]\n",
    "len(gene_experssion_features), len(cell_viability_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = tr.drop(['sig_id', 'cp_type', 'cp_time', 'cp_dose'], axis=1)\n",
    "te = test_features.drop(['sig_id', 'cp_type', 'cp_time', 'cp_dose'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T07:45:29.048267Z",
     "iopub.status.busy": "2020-11-11T07:45:29.046389Z",
     "iopub.status.idle": "2020-11-11T07:45:29.049041Z",
     "shell.execute_reply": "2020-11-11T07:45:29.049614Z"
    },
    "papermill": {
     "duration": 0.056399,
     "end_time": "2020-11-11T07:45:29.049751",
     "exception": false,
     "start_time": "2020-11-11T07:45:28.993352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocessor_1(train, valid, test, seed):\n",
    "    n_gs = 2\n",
    "    n_cs = 100\n",
    "\n",
    "    # g-mean, c-mean\n",
    "    train_g_mean = train[gene_experssion_features].mean(axis=1)\n",
    "    valid_g_mean = valid[gene_experssion_features].mean(axis=1)\n",
    "    test_g_mean = test[gene_experssion_features].mean(axis=1)\n",
    "\n",
    "    train_c_mean = train[cell_viability_features].mean(axis=1)\n",
    "    valid_c_mean = valid[cell_viability_features].mean(axis=1)\n",
    "    test_c_mean = test[cell_viability_features].mean(axis=1)\n",
    "\n",
    "    train_columns = train.columns.tolist()\n",
    "    test_columns = test.columns.tolist()\n",
    "\n",
    "    train = np.concatenate(\n",
    "        (train, train_g_mean[:, np.newaxis], train_c_mean[:, np.newaxis]),\n",
    "        axis=1)\n",
    "    valid = np.concatenate(\n",
    "        (valid, valid_g_mean[:, np.newaxis], valid_c_mean[:, np.newaxis]),\n",
    "        axis=1)\n",
    "    test = np.concatenate(\n",
    "        (test, test_g_mean[:, np.newaxis], test_c_mean[:, np.newaxis]), axis=1)\n",
    "\n",
    "    # Standard Scaler for Numerical Values\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    train = pd.DataFrame(data=scaler.fit_transform(train),\n",
    "                         columns=train_columns + [\"g_mean\", \"c_mean\"])\n",
    "    valid = pd.DataFrame(data=scaler.transform(valid),\n",
    "                         columns=train_columns + [\"g_mean\", \"c_mean\"])\n",
    "    test = pd.DataFrame(data=scaler.transform(test),\n",
    "                        columns=test_columns + [\"g_mean\", \"c_mean\"])\n",
    "\n",
    "    pca_gs = PCA(n_components=n_gs, random_state=seed)\n",
    "    train_pca_gs = pca_gs.fit_transform(train[gene_experssion_features].values)\n",
    "    valid_pca_gs = pca_gs.transform(valid[gene_experssion_features].values)\n",
    "    test_pca_gs = pca_gs.transform(test[gene_experssion_features].values)\n",
    "\n",
    "    pca_cs = PCA(n_components=n_cs, random_state=seed)\n",
    "    train_pca_cs = pca_cs.fit_transform(train[cell_viability_features].values)\n",
    "    valid_pca_cs = pca_cs.transform(valid[cell_viability_features].values)\n",
    "    test_pca_cs = pca_cs.transform(test[cell_viability_features].values)\n",
    "\n",
    "    # Append Features\n",
    "    train = np.concatenate((train, train_pca_gs, train_pca_cs), axis=1)\n",
    "    valid = np.concatenate((valid, valid_pca_gs, valid_pca_cs), axis=1)\n",
    "    test = np.concatenate((test, test_pca_gs, test_pca_cs), axis=1)\n",
    "\n",
    "    return train, valid, test, scaler, pca_gs, pca_cs\n",
    "\n",
    "\n",
    "def preprocessor_2(train, valid, test):\n",
    "    # Standard Scaler for Numerical Values\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    train = scaler.fit_transform(train)\n",
    "    valid = scaler.transform(valid)\n",
    "    test = scaler.transform(test)\n",
    "\n",
    "    return train, valid, test, scaler\n",
    "\n",
    "\n",
    "def save_pickle(obj, name):\n",
    "    dump(obj, open(f\"{name}.pkl\", 'wb'), pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def load_pickle(name):\n",
    "    return load(open(f\"{name}.pkl\", 'rb'))\n",
    "\n",
    "\n",
    "def mean_logloss(y_pred, y_true):\n",
    "    logloss = (1 - y_true) * np.log(1 - y_pred +\n",
    "                                    1e-15) + y_true * np.log(y_pred + 1e-15)\n",
    "    return np.mean(-logloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21948, 872), (3982, 872))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr.shape, te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T07:45:30.295979Z",
     "iopub.status.busy": "2020-11-11T07:45:30.274930Z",
     "iopub.status.idle": "2020-11-11T08:45:30.221121Z",
     "shell.execute_reply": "2020-11-11T08:45:30.220025Z"
    },
    "papermill": {
     "duration": 3600.006513,
     "end_time": "2020-11-11T08:45:30.221259",
     "exception": false,
     "start_time": "2020-11-11T07:45:30.214746",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After non-scored training: validation_loss = 0.006330415140837431\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "After scored training: validation_loss = 0.018055442720651627\n",
      "Before loop: validation_loss = 0.018055442720651627\n",
      "No Improvement, stopped\n",
      "1 loop ---> After Frozen-step best valid = 0.018055442720651627 after 3 epochs \n",
      "\n",
      "Improved: 0.018036017194390297\n",
      "Improved: 0.018024910241365433\n",
      "Improved: 0.018018774688243866\n",
      "Improved: 0.018015798181295395\n",
      "Improved: 0.018013080582022667\n",
      "Improved: 0.01801231876015663\n",
      "Improved: 0.01801210455596447\n",
      "No Improvement, stopped\n",
      "1 loop ---> After Non-frozen-step best valid = 0.018012210726737976 after 7 epochs \n",
      "\n",
      "Total Non-frozen-step improved: 7\n",
      "No Improvement, stopped\n",
      "2 loop ---> After Frozen-step best valid = 0.01801210455596447 after 3 epochs \n",
      "\n",
      "No Improvement, stopped\n",
      "2 loop ---> After Non-frozen-step best valid = 0.01801699586212635 after 3 epochs \n",
      "\n",
      "Total Non-frozen-step improved: 0\n",
      "\n",
      "Seed: 23 Fold: 0 score: 0.01634207889291769\n",
      "[[0.00054113 0.00140265 0.00118063 ... 0.00122656 0.00074099 0.00088059]\n",
      " [0.0008154  0.00183683 0.0013612  ... 0.00161495 0.00192306 0.00185741]\n",
      " [0.00079182 0.00061498 0.00271417 ... 0.00103438 0.00276128 0.00424087]\n",
      " [0.00033531 0.00068183 0.00088591 ... 0.00062417 0.00456159 0.00209774]\n",
      " [0.001978   0.00086583 0.00100117 ... 0.00148697 0.00024657 0.00047437]]\n",
      "\n",
      "\n",
      "After non-scored training: validation_loss = 0.006209765560925007\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "After scored training: validation_loss = 0.018412450328469276\n",
      "Before loop: validation_loss = 0.018412450328469276\n",
      "No Improvement, stopped\n",
      "1 loop ---> After Frozen-step best valid = 0.018412450328469276 after 3 epochs \n",
      "\n",
      "Improved: 0.018391786143183708\n",
      "Improved: 0.01837901771068573\n",
      "Improved: 0.018370898440480232\n",
      "Improved: 0.0183658916503191\n",
      "Improved: 0.018362557515501976\n",
      "Improved: 0.018361616879701614\n",
      "Improved: 0.01836126670241356\n",
      "No Improvement, stopped\n",
      "1 loop ---> After Non-frozen-step best valid = 0.018361685797572136 after 7 epochs \n",
      "\n",
      "Total Non-frozen-step improved: 7\n",
      "No Improvement, stopped\n",
      "2 loop ---> After Frozen-step best valid = 0.01836126670241356 after 3 epochs \n",
      "\n",
      "Improved: 0.018360184505581856\n",
      "No Improvement, stopped\n",
      "2 loop ---> After Non-frozen-step best valid = 0.018360791727900505 after 3 epochs \n",
      "\n",
      "Total Non-frozen-step improved: 1\n",
      "No Improvement, stopped\n",
      "3 loop ---> After Frozen-step best valid = 0.018360184505581856 after 3 epochs \n",
      "\n",
      "Improved: 0.018359605222940445\n",
      "No Improvement, stopped\n",
      "3 loop ---> After Non-frozen-step best valid = 0.018360840156674385 after 3 epochs \n",
      "\n",
      "Total Non-frozen-step improved: 1\n",
      "No Improvement, stopped\n",
      "4 loop ---> After Frozen-step best valid = 0.018359605222940445 after 3 epochs \n",
      "\n",
      "Improved: 0.018359320238232613\n",
      "No Improvement, stopped\n",
      "4 loop ---> After Non-frozen-step best valid = 0.018360955640673637 after 3 epochs \n",
      "\n",
      "Total Non-frozen-step improved: 1\n",
      "No Improvement, stopped\n",
      "5 loop ---> After Frozen-step best valid = 0.018359320238232613 after 3 epochs \n",
      "\n",
      "Improved: 0.018359268084168434\n",
      "No Improvement, stopped\n",
      "5 loop ---> After Non-frozen-step best valid = 0.01836111769080162 after 3 epochs \n",
      "\n",
      "Total Non-frozen-step improved: 1\n",
      "No Improvement, stopped\n",
      "6 loop ---> After Frozen-step best valid = 0.018359268084168434 after 3 epochs \n",
      "\n",
      "No Improvement, stopped\n",
      "6 loop ---> After Non-frozen-step best valid = 0.018361294642090797 after 3 epochs \n",
      "\n",
      "Total Non-frozen-step improved: 0\n",
      "\n",
      "Seed: 23 Fold: 1 score: 0.016739491665900053\n",
      "[[0.00143393 0.0012716  0.00201634 ... 0.0035781  0.00452373 0.00291195]\n",
      " [0.00093042 0.0010173  0.00068453 ... 0.00054141 0.00764267 0.00098794]\n",
      " [0.00055781 0.00042301 0.00193442 ... 0.00478792 0.00224463 0.00784279]\n",
      " [0.00304879 0.0012371  0.00302354 ... 0.00445702 0.00139638 0.00209533]\n",
      " [0.00098468 0.00168559 0.0024103  ... 0.00359692 0.00110711 0.00236714]]\n",
      "\n",
      "\n",
      "After non-scored training: validation_loss = 0.005997982807457447\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00018: early stopping\n",
      "After scored training: validation_loss = 0.01818905957043171\n",
      "Before loop: validation_loss = 0.01818905957043171\n",
      "No Improvement, stopped\n",
      "1 loop ---> After Frozen-step best valid = 0.01818905957043171 after 3 epochs \n",
      "\n",
      "Improved: 0.018183249980211258\n",
      "Improved: 0.018182076513767242\n",
      "No Improvement, stopped\n",
      "1 loop ---> After Non-frozen-step best valid = 0.01818740740418434 after 3 epochs \n",
      "\n",
      "Total Non-frozen-step improved: 2\n",
      "No Improvement, stopped\n",
      "2 loop ---> After Frozen-step best valid = 0.018182076513767242 after 3 epochs \n",
      "\n",
      "No Improvement, stopped\n",
      "2 loop ---> After Non-frozen-step best valid = 0.018197905272245407 after 3 epochs \n",
      "\n",
      "Total Non-frozen-step improved: 0\n",
      "\n",
      "Seed: 23 Fold: 2 score: 0.01647970505696522\n",
      "[[9.1117620e-04 1.1138991e-03 4.9236109e-03 ... 4.3316833e-03\n",
      "  1.6776122e-03 1.5872637e-03]\n",
      " [8.8648754e-05 3.7377959e-04 1.4741913e-03 ... 8.0467190e-04\n",
      "  1.1084316e-02 2.3038194e-03]\n",
      " [6.9178635e-04 2.5661639e-04 2.8841947e-03 ... 2.9978727e-03\n",
      "  1.0258157e-03 9.3725929e-03]\n",
      " [3.0136122e-03 3.2618691e-04 3.2353804e-03 ... 1.4923391e-03\n",
      "  3.1072726e-03 7.3090233e-03]\n",
      " [1.6545232e-03 2.1093898e-03 1.1360991e-03 ... 2.2039844e-03\n",
      "  6.5917411e-04 1.0178607e-03]]\n",
      "\n",
      "\n",
      "After non-scored training: validation_loss = 0.006298057269304991\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "After scored training: validation_loss = 0.01839629001915455\n",
      "Before loop: validation_loss = 0.01839629001915455\n",
      "No Improvement, stopped\n",
      "1 loop ---> After Frozen-step best valid = 0.01839629001915455 after 3 epochs \n",
      "\n",
      "No Improvement, stopped\n",
      "1 loop ---> After Non-frozen-step best valid = 0.01840982213616371 after 3 epochs \n",
      "\n",
      "Total Non-frozen-step improved: 0\n",
      "\n",
      "Seed: 23 Fold: 3 score: 0.016791168364675153\n",
      "[[0.00311191 0.001457   0.00176618 ... 0.00124919 0.00175493 0.00148997]\n",
      " [0.00021451 0.000965   0.00027131 ... 0.00023927 0.00136574 0.00040742]\n",
      " [0.00295509 0.00149787 0.00423104 ... 0.00358821 0.00177495 0.00254064]\n",
      " [0.00193013 0.0013717  0.00149071 ... 0.00243189 0.00237834 0.00186554]\n",
      " [0.00432446 0.00266437 0.0022139  ... 0.00163834 0.00050613 0.00145862]]\n",
      "\n",
      "\n",
      "After non-scored training: validation_loss = 0.00601543951779604\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "After scored training: validation_loss = 0.01892586052417755\n",
      "Before loop: validation_loss = 0.01892586052417755\n",
      "No Improvement, stopped\n",
      "1 loop ---> After Frozen-step best valid = 0.01892586052417755 after 3 epochs \n",
      "\n",
      "Improved: 0.01891382783651352\n",
      "Improved: 0.01890779286623001\n",
      "Improved: 0.018904821947216988\n",
      "No Improvement, stopped\n",
      "1 loop ---> After Non-frozen-step best valid = 0.018906300887465477 after 3 epochs \n",
      "\n",
      "Total Non-frozen-step improved: 3\n",
      "No Improvement, stopped\n",
      "2 loop ---> After Frozen-step best valid = 0.018904821947216988 after 3 epochs \n",
      "\n",
      "No Improvement, stopped\n",
      "2 loop ---> After Non-frozen-step best valid = 0.018916383385658264 after 3 epochs \n",
      "\n",
      "Total Non-frozen-step improved: 0\n",
      "\n",
      "Seed: 23 Fold: 4 score: 0.017231570234408865\n",
      "[[0.00110146 0.00044757 0.00141805 ... 0.00167557 0.00624667 0.00306113]\n",
      " [0.00183894 0.00083788 0.0010072  ... 0.00051056 0.0155346  0.00069796]\n",
      " [0.00073913 0.00017354 0.00222147 ... 0.00382601 0.00188145 0.00532663]\n",
      " [0.00062199 0.00071447 0.00151981 ... 0.0023712  0.0005888  0.0034934 ]\n",
      " [0.00149011 0.0012761  0.00226288 ... 0.00185268 0.00040952 0.00131042]]\n",
      "\n",
      "\n",
      "After non-scored training: validation_loss = 0.005945626646280289\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "After scored training: validation_loss = 0.018491914495825768\n",
      "Before loop: validation_loss = 0.018491914495825768\n",
      "No Improvement, stopped\n",
      "1 loop ---> After Frozen-step best valid = 0.018491914495825768 after 3 epochs \n",
      "\n",
      "Improved: 0.01848466508090496\n",
      "Improved: 0.018481675535440445\n",
      "Improved: 0.01848076470196247\n",
      "No Improvement, stopped\n",
      "1 loop ---> After Non-frozen-step best valid = 0.018482306972146034 after 3 epochs \n",
      "\n",
      "Total Non-frozen-step improved: 3\n",
      "No Improvement, stopped\n",
      "2 loop ---> After Frozen-step best valid = 0.01848076470196247 after 3 epochs \n",
      "\n",
      "No Improvement, stopped\n",
      "2 loop ---> After Non-frozen-step best valid = 0.018490390852093697 after 3 epochs \n",
      "\n",
      "Total Non-frozen-step improved: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Seed: 23 Fold: 5 score: 0.01690727124263891\n",
      "[[0.00071842 0.00173025 0.00103136 ... 0.00117915 0.01343292 0.00241463]\n",
      " [0.00067068 0.00068698 0.00131071 ... 0.00217135 0.00073994 0.00857495]\n",
      " [0.00365388 0.00282702 0.00486645 ... 0.01138465 0.01260079 0.00501033]\n",
      " [0.00135423 0.00127508 0.0019099  ... 0.00167528 0.00437366 0.00272277]\n",
      " [0.00269766 0.00207258 0.0016012  ... 0.00255441 0.00111163 0.00300019]]\n",
      "\n",
      "\n",
      "After non-scored training: validation_loss = 0.006359836086630821\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "After scored training: validation_loss = 0.01760777458548546\n",
      "Before loop: validation_loss = 0.01760777458548546\n",
      "No Improvement, stopped\n",
      "1 loop ---> After Frozen-step best valid = 0.01760777458548546 after 3 epochs \n",
      "\n",
      "No Improvement, stopped\n",
      "1 loop ---> After Non-frozen-step best valid = 0.01764295995235443 after 3 epochs \n",
      "\n",
      "Total Non-frozen-step improved: 0\n",
      "\n",
      "Seed: 23 Fold: 6 score: 0.015980884198794267\n",
      "[[0.00296811 0.00138372 0.00118677 ... 0.00131576 0.00046952 0.00164685]\n",
      " [0.00117143 0.00124318 0.00074751 ... 0.00131482 0.00701815 0.00127371]\n",
      " [0.00073977 0.00022934 0.00320189 ... 0.00338231 0.0009025  0.00144154]\n",
      " [0.00142146 0.0004453  0.00115989 ... 0.00248173 0.0017457  0.0010318 ]\n",
      " [0.00207159 0.00042627 0.00124013 ... 0.00325702 0.00066544 0.00195785]]\n",
      "\n",
      "\n",
      "After non-scored training: validation_loss = 0.00626940093934536\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "After scored training: validation_loss = 0.018261680379509926\n",
      "Before loop: validation_loss = 0.018261680379509926\n",
      "No Improvement, stopped\n",
      "1 loop ---> After Frozen-step best valid = 0.018261680379509926 after 3 epochs \n",
      "\n",
      "Improved: 0.018243351951241493\n",
      "Improved: 0.018232205882668495\n",
      "Improved: 0.018227674067020416\n",
      "Improved: 0.01822746731340885\n",
      "No Improvement, stopped\n",
      "1 loop ---> After Non-frozen-step best valid = 0.01822795905172825 after 4 epochs \n",
      "\n",
      "Total Non-frozen-step improved: 4\n",
      "No Improvement, stopped\n",
      "2 loop ---> After Frozen-step best valid = 0.01822746731340885 after 3 epochs \n",
      "\n",
      "No Improvement, stopped\n",
      "2 loop ---> After Non-frozen-step best valid = 0.01823655515909195 after 3 epochs \n",
      "\n",
      "Total Non-frozen-step improved: 0\n",
      "\n",
      "Seed: 23 Fold: 7 score: 0.016613233956883102\n",
      "[[0.00092117 0.00038955 0.0008804  ... 0.0025295  0.00309085 0.00368112]\n",
      " [0.00091037 0.00061673 0.00100796 ... 0.0013954  0.00551387 0.00767683]\n",
      " [0.00064474 0.00042438 0.00180001 ... 0.00448539 0.00687144 0.00099546]\n",
      " [0.00076266 0.00024423 0.00071905 ... 0.00150195 0.00132942 0.00073054]\n",
      " [0.00118811 0.00058106 0.00299872 ... 0.00138877 0.00424267 0.00222437]]\n",
      "\n",
      "\n",
      "After non-scored training: validation_loss = 0.006048926617950201\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "After scored training: validation_loss = 0.0181965921074152\n",
      "Before loop: validation_loss = 0.0181965921074152\n",
      "No Improvement, stopped\n",
      "1 loop ---> After Frozen-step best valid = 0.0181965921074152 after 3 epochs \n",
      "\n",
      "Improved: 0.01817019283771515\n",
      "Improved: 0.018152015283703804\n",
      "Improved: 0.018142014741897583\n",
      "Improved: 0.018136072903871536\n",
      "Improved: 0.01813305728137493\n",
      "Improved: 0.01813158206641674\n",
      "No Improvement, stopped\n",
      "1 loop ---> After Non-frozen-step best valid = 0.018131770193576813 after 6 epochs \n",
      "\n",
      "Total Non-frozen-step improved: 6\n",
      "No Improvement, stopped\n",
      "2 loop ---> After Frozen-step best valid = 0.01813158206641674 after 3 epochs \n",
      "\n",
      "Improved: 0.01813058741390705\n",
      "No Improvement, stopped\n",
      "2 loop ---> After Non-frozen-step best valid = 0.01813284493982792 after 3 epochs \n",
      "\n",
      "Total Non-frozen-step improved: 1\n",
      "No Improvement, stopped\n",
      "3 loop ---> After Frozen-step best valid = 0.01813058741390705 after 3 epochs \n",
      "\n",
      "No Improvement, stopped\n",
      "3 loop ---> After Non-frozen-step best valid = 0.018134625628590584 after 3 epochs \n",
      "\n",
      "Total Non-frozen-step improved: 0\n",
      "\n",
      "Seed: 23 Fold: 8 score: 0.016466023085256826\n",
      "[[6.78267970e-04 1.59163587e-03 1.58306456e-03 ... 4.47126385e-03\n",
      "  2.43703974e-03 1.76048977e-03]\n",
      " [1.00002384e-04 4.02771038e-05 2.89250747e-03 ... 1.31792534e-04\n",
      "  2.49968050e-03 9.30594615e-05]\n",
      " [3.26306326e-04 3.49920650e-04 3.04929144e-03 ... 1.29253268e-02\n",
      "  1.86074234e-03 4.18789778e-03]\n",
      " [1.11663365e-03 1.00273406e-03 4.56642173e-03 ... 4.39343555e-03\n",
      "  2.13214313e-03 7.61559047e-03]\n",
      " [2.58806278e-03 2.40030419e-03 7.83075672e-03 ... 4.04266734e-03\n",
      "  3.19482468e-04 7.97143439e-04]]\n",
      "\n",
      "\n",
      "After non-scored training: validation_loss = 0.006285614334046841\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "After scored training: validation_loss = 0.018454881384968758\n",
      "Before loop: validation_loss = 0.018454881384968758\n",
      "No Improvement, stopped\n",
      "1 loop ---> After Frozen-step best valid = 0.018454881384968758 after 3 epochs \n",
      "\n",
      "Improved: 0.018439706414937973\n",
      "Improved: 0.01843046396970749\n",
      "Improved: 0.01842677779495716\n",
      "Improved: 0.018424898386001587\n",
      "No Improvement, stopped\n",
      "1 loop ---> After Non-frozen-step best valid = 0.01842539943754673 after 4 epochs \n",
      "\n",
      "Total Non-frozen-step improved: 4\n",
      "No Improvement, stopped\n",
      "2 loop ---> After Frozen-step best valid = 0.018424898386001587 after 3 epochs \n",
      "\n",
      "No Improvement, stopped\n",
      "2 loop ---> After Non-frozen-step best valid = 0.018434004858136177 after 3 epochs \n",
      "\n",
      "Total Non-frozen-step improved: 0\n",
      "\n",
      "Seed: 23 Fold: 9 score: 0.016758988798337406\n",
      "[[0.00065988 0.00023444 0.00216425 ... 0.00232858 0.00568886 0.00112462]\n",
      " [0.00029356 0.00110496 0.00109116 ... 0.00071885 0.00238921 0.00039848]\n",
      " [0.00114192 0.00077304 0.00249773 ... 0.00176757 0.00113426 0.00321451]\n",
      " [0.00180122 0.00077404 0.00115198 ... 0.00110564 0.00070521 0.00181482]\n",
      " [0.00106524 0.00042608 0.00135446 ... 0.00127085 0.00017222 0.00114773]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oof_predictions = np.zeros((tr.shape[0], Y.shape[1]))\n",
    "\n",
    "y_pred = np.zeros((te.shape[0], 206))\n",
    "for s in SEEDS:\n",
    "\n",
    "    random.seed(s)\n",
    "    np.random.seed(s)\n",
    "    tf.random.set_seed(s)\n",
    "\n",
    "    k = 0\n",
    "    kf = KFold(n_splits=KFOLDS, shuffle=True, random_state=s)\n",
    "    for train_index, valid_index in kf.split(tr):\n",
    "        file_name = f\"seed{s}_fold{k}\"\n",
    "\n",
    "        X_train_1, X_valid_1, X_test_1, scaler_1, pca_gs, pca_cs = preprocessor_1(\n",
    "            tr.iloc[train_index, :], tr.iloc[valid_index, :], te, s)\n",
    "        save_pickle(scaler_1, f\"{file_name}_scaler_1\")\n",
    "        save_pickle(pca_gs, f\"{file_name}_pca_gs\")\n",
    "        save_pickle(pca_cs, f\"{file_name}_pca_cs\")\n",
    "\n",
    "        X_train_2, X_valid_2, X_test_2, scaler_2 = preprocessor_2(\n",
    "            second_Xtrain[train_index, :], second_Xtrain[valid_index, :],\n",
    "            second_Xtest)\n",
    "        save_pickle(scaler_2, f\"{file_name}_scaler_2\")\n",
    "\n",
    "        y_train_1, y_valid_1 = Y[train_index, :], Y[valid_index, :]\n",
    "        y_train_2, y_valid_2 = Y0[train_index, :], Y0[valid_index, :]\n",
    "\n",
    "        n_features = X_train_1.shape[1]\n",
    "        n_features_2 = X_train_2.shape[1]\n",
    "\n",
    "        early_stopping = callbacks.EarlyStopping(min_delta=1e-5,\n",
    "                                                 monitor='val_loss',\n",
    "                                                 patience=10,\n",
    "                                                 verbose=0,\n",
    "                                                 mode='min',\n",
    "                                                 restore_best_weights=True)\n",
    "        check_point = callbacks.ModelCheckpoint(f\"{file_name}_nonscore.h5\",\n",
    "                                                save_best_only=True,\n",
    "                                                verbose=0,\n",
    "                                                mode=\"min\")\n",
    "        reduce_lr = callbacks.ReduceLROnPlateau(factor=0.5,\n",
    "                                                patience=4,\n",
    "                                                verbose=0,\n",
    "                                                mode=\"auto\")\n",
    "\n",
    "        # Model Definition #\n",
    "\n",
    "        input1_ = layers.Input(shape=(n_features, ))\n",
    "        input2_ = layers.Input(shape=(n_features_2, ))\n",
    "\n",
    "        output1 = Sequential([\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(0.2),\n",
    "            layers.Dense(512, activation=\"elu\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(256, activation=\"elu\")\n",
    "        ])(input1_)\n",
    "\n",
    "        answer1 = Sequential([\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(512, \"relu\")\n",
    "        ])(layers.Concatenate()([output1, input2_]))\n",
    "\n",
    "        answer2 = Sequential([\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(512, \"elu\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(256, \"relu\")\n",
    "        ])(layers.Concatenate()([output1, input2_, answer1]))\n",
    "\n",
    "        answer3 = Sequential(\n",
    "            [layers.BatchNormalization(),\n",
    "             layers.Dense(256,\n",
    "                          \"elu\")])(layers.Concatenate()([answer1, answer2]))\n",
    "\n",
    "        answer3_ = Sequential([\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(256, \"relu\")\n",
    "        ])(layers.Concatenate()([answer1, answer2, answer3]))\n",
    "\n",
    "        answer4 = Sequential([\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(\n",
    "                256,\n",
    "                kernel_initializer=tf.keras.initializers.lecun_normal(seed=s),\n",
    "                activation='selu',\n",
    "                name='last_frozen'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(\n",
    "                206,\n",
    "                kernel_initializer=tf.keras.initializers.lecun_normal(seed=s),\n",
    "                activation='selu')\n",
    "        ])(layers.Concatenate()([output1, answer2, answer3, answer3_]))\n",
    "\n",
    "        # Non-scored Training #\n",
    "\n",
    "        answer5 = Sequential([\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(Y0.shape[1], \"sigmoid\")\n",
    "        ])(answer4)\n",
    "\n",
    "        m_nn = tf.keras.Model([input1_, input2_], answer5)\n",
    "\n",
    "        m_nn.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "                     loss=losses.BinaryCrossentropy(\n",
    "                         label_smoothing=label_smoothing_alpha),\n",
    "                     metrics=logloss)\n",
    "\n",
    "        history = m_nn.fit([X_train_1, X_train_2],\n",
    "                           y_train_2,\n",
    "                           epochs=50,\n",
    "                           batch_size=128,\n",
    "                           validation_data=([X_valid_1, X_valid_2], y_valid_2),\n",
    "                           callbacks=[check_point, early_stopping, reduce_lr],\n",
    "                           verbose=0)\n",
    "        m_nn = tf.keras.models.load_model(f\"{file_name}_nonscore.h5\",\n",
    "                                          custom_objects={'logloss': logloss})\n",
    "\n",
    "        valid_metric_old = m_nn.evaluate([X_valid_1, X_valid_2],\n",
    "                                         y_valid_2,\n",
    "                                         verbose=0)[0]  # loss\n",
    "        print('After non-scored training: validation_loss =', valid_metric_old)\n",
    "\n",
    "        # Scored Training #\n",
    "\n",
    "        answer5 = Sequential(\n",
    "            [layers.BatchNormalization(),\n",
    "             layers.Dense(Y.shape[1], \"sigmoid\")])(answer4)\n",
    "\n",
    "        m_nn = tf.keras.Model([input1_, input2_], answer5)\n",
    "\n",
    "        m_nn.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "                     loss=losses.BinaryCrossentropy(\n",
    "                         label_smoothing=label_smoothing_alpha),\n",
    "                     metrics=logloss)\n",
    "\n",
    "        early_stopping = callbacks.EarlyStopping(min_delta=1e-5,\n",
    "                                                 monitor='val_loss',\n",
    "                                                 patience=10,\n",
    "                                                 verbose=1,\n",
    "                                                 mode='min',\n",
    "                                                 restore_best_weights=True)\n",
    "        check_point = callbacks.ModelCheckpoint(f\"{file_name}.h5\",\n",
    "                                                save_best_only=True,\n",
    "                                                verbose=0,\n",
    "                                                mode=\"min\")\n",
    "        reduce_lr = callbacks.ReduceLROnPlateau(factor=0.5,\n",
    "                                                patience=4,\n",
    "                                                verbose=0,\n",
    "                                                mode=\"auto\")\n",
    "\n",
    "        history = m_nn.fit([X_train_1, X_train_2],\n",
    "                           y_train_1,\n",
    "                           epochs=50,\n",
    "                           batch_size=128,\n",
    "                           validation_data=([X_valid_1, X_valid_2], y_valid_1),\n",
    "                           callbacks=[check_point, early_stopping, reduce_lr],\n",
    "                           verbose=0)\n",
    "        m_nn = tf.keras.models.load_model(f\"{file_name}.h5\",\n",
    "                                          custom_objects={'logloss': logloss})\n",
    "\n",
    "        # val_old = m_nn.predict([X_valid_1, X_valid_2])\n",
    "        # valid_metric_old = mean_logloss(val_old, y_valid_1)\n",
    "        valid_metric_old = m_nn.evaluate([X_valid_1, X_valid_2],\n",
    "                                         y_valid_1,\n",
    "                                         verbose=0)[0]  # loss\n",
    "        print('After scored training: validation_loss =', valid_metric_old)\n",
    "\n",
    "        m_nn.save('tmp.h5')\n",
    "\n",
    "        print('Before loop: validation_loss =', valid_metric_old)\n",
    "\n",
    "        # big loop\n",
    "        loop = 1\n",
    "        while True:\n",
    "            # Freeze_weights(m_nn, to = 'last_frozen')\n",
    "            for i, layer in enumerate(m_nn.layers):\n",
    "                if layer.name == \"last_frozen\":\n",
    "                    layer.trainable = True\n",
    "                    break\n",
    "                else:\n",
    "                    layer.trainable = False\n",
    "\n",
    "            m_nn.compile(optimizer=tf.keras.optimizers.Adadelta(lr=0.001 / 3),\n",
    "                         loss=tf.losses.BinaryCrossentropy(\n",
    "                             label_smoothing=label_smoothing_alpha),\n",
    "                         metrics=logloss)\n",
    "\n",
    "            # Frozen Mode #\n",
    "\n",
    "            reps = 0\n",
    "            improved = 0\n",
    "            patience = 3\n",
    "            while True:\n",
    "                history = m_nn.fit([X_valid_1, X_valid_2],\n",
    "                                   y_valid_1,\n",
    "                                   epochs=1,\n",
    "                                   batch_size=128,\n",
    "                                   verbose=0)\n",
    "\n",
    "                # val_preds = m_nn.predict([X_valid_1, X_valid_2])\n",
    "                # valid_metric = mean_logloss(val_preds, y_valid_1)\n",
    "                valid_metric = m_nn.evaluate([X_valid_1, X_valid_2],\n",
    "                                             y_valid_1,\n",
    "                                             verbose=0)[0]\n",
    "\n",
    "                if valid_metric_old > valid_metric:\n",
    "                    print('Improved:', valid_metric)\n",
    "                    reps = reps + 1\n",
    "                    improved += 1\n",
    "                    valid_metric_old = valid_metric\n",
    "                    m_nn.save('tmp.h5')\n",
    "                elif reps < patience:\n",
    "                    reps = reps + 1\n",
    "                    pass\n",
    "                else:\n",
    "                    print('No Improvement, stopped')\n",
    "                    m_nn = tf.keras.models.load_model(\n",
    "                        'tmp.h5', custom_objects={'logloss': logloss})\n",
    "                    print(loop, 'loop ---> After Frozen-step best valid =',\n",
    "                          valid_metric_old, 'after', reps, 'epochs \\n')\n",
    "\n",
    "                    break\n",
    "\n",
    "            # Should continue training instead?\n",
    "            # if (improved == 0):  # no progress? STOP!\n",
    "            #     break\n",
    "\n",
    "            # Unfrozen Mode #\n",
    "\n",
    "            # Unfreeze all layers\n",
    "            for i, layer in enumerate(m_nn.layers):\n",
    "                layer.trainable = True\n",
    "\n",
    "            m_nn.compile(optimizer=tf.keras.optimizers.Adadelta(lr=0.001 / 5),\n",
    "                         loss=tf.losses.BinaryCrossentropy(\n",
    "                             label_smoothing=label_smoothing_alpha),\n",
    "                         metrics=logloss)\n",
    "\n",
    "            reps = 0\n",
    "            improved = 0\n",
    "            patience = 3\n",
    "            while True:\n",
    "                history = m_nn.fit([X_valid_1, X_valid_2],\n",
    "                                   y_valid_1,\n",
    "                                   epochs=1,\n",
    "                                   batch_size=128,\n",
    "                                   verbose=0)\n",
    "\n",
    "                # val_preds = m_nn.predict([X_valid_1, X_valid_2])\n",
    "                # valid_metric = mean_logloss(val_preds, y_valid_1)\n",
    "                valid_metric = m_nn.evaluate([X_valid_1, X_valid_2],\n",
    "                                             y_valid_1,\n",
    "                                             verbose=0)[0]\n",
    "\n",
    "                if valid_metric_old > valid_metric:\n",
    "                    print('Improved:', valid_metric)\n",
    "                    reps = reps + 1\n",
    "                    improved += 1\n",
    "                    valid_metric_old = valid_metric\n",
    "                    m_nn.save('tmp.h5')\n",
    "                elif reps < patience:\n",
    "                    reps = reps + 1\n",
    "                    pass\n",
    "                else:\n",
    "                    print('No Improvement, stopped')\n",
    "                    m_nn = tf.keras.models.load_model(\n",
    "                        'tmp.h5', custom_objects={'logloss': logloss})\n",
    "                    print(loop, 'loop ---> After Non-frozen-step best valid =',\n",
    "                          valid_metric, 'after', reps, 'epochs \\n')\n",
    "\n",
    "                    break\n",
    "\n",
    "            print(\"Total Non-frozen-step improved:\", improved)\n",
    "            if (improved == 0):\n",
    "                break\n",
    "\n",
    "            loop = loop + 1\n",
    "\n",
    "        # Save Final Model\n",
    "        m_nn.save(f'{file_name}_final.h5')\n",
    "\n",
    "        # OOF Predictions and Score #\n",
    "\n",
    "        val_preds = m_nn.predict([X_valid_1, X_valid_2])\n",
    "        fold_valid_score = mean_logloss(val_preds, y_valid_1)\n",
    "\n",
    "        oof_predictions[valid_index, :] += val_preds / len(SEEDS)\n",
    "        print('\\nSeed:', s, 'Fold:', k, 'score:', fold_valid_score)\n",
    "\n",
    "        # Generate Submission Prediction #\n",
    "        fold_submit_preds = m_nn.predict([X_test_1, X_test_2])\n",
    "        y_pred += fold_submit_preds / (KFOLDS * len(SEEDS))\n",
    "        print(fold_submit_preds[:5, :])\n",
    "\n",
    "        k += 1\n",
    "\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T08:46:27.991646Z",
     "iopub.status.busy": "2020-11-11T08:46:27.990901Z",
     "iopub.status.idle": "2020-11-11T08:46:28.000205Z",
     "shell.execute_reply": "2020-11-11T08:46:28.002353Z"
    },
    "papermill": {
     "duration": 14.092036,
     "end_time": "2020-11-11T08:46:28.002567",
     "exception": false,
     "start_time": "2020-11-11T08:46:13.910531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF Validation Loss: 0.016631\n"
     ]
    }
   ],
   "source": [
    "oof_loss = mean_logloss(oof_predictions, Y)\n",
    "print(f\"OOF Validation Loss: {oof_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 206)\n"
     ]
    }
   ],
   "source": [
    "with open(f'oof_{oof_loss}.npy', 'wb') as f:\n",
    "    np.save(f, oof_predictions)\n",
    "\n",
    "with open(f'oof_{oof_loss}.npy', 'rb') as f:\n",
    "    tmp = np.load(f)\n",
    "    print(tmp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 13.933663,
     "end_time": "2020-11-11T08:46:56.745720",
     "exception": false,
     "start_time": "2020-11-11T08:46:42.812057",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T08:48:54.311631Z",
     "iopub.status.busy": "2020-11-11T08:48:54.310535Z",
     "iopub.status.idle": "2020-11-11T08:48:54.916705Z",
     "shell.execute_reply": "2020-11-11T08:48:54.916073Z"
    },
    "papermill": {
     "duration": 14.67484,
     "end_time": "2020-11-11T08:48:54.916824",
     "exception": false,
     "start_time": "2020-11-11T08:48:40.241984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub.iloc[:, 1:] = y_pred\n",
    "# sub.iloc[:, 1:] = np.clip(y_pred, P_MIN, P_MAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T08:49:24.916192Z",
     "iopub.status.busy": "2020-11-11T08:49:24.915133Z",
     "iopub.status.idle": "2020-11-11T08:49:24.955202Z",
     "shell.execute_reply": "2020-11-11T08:49:24.955799Z"
    },
    "papermill": {
     "duration": 14.848436,
     "end_time": "2020-11-11T08:49:24.955970",
     "exception": false,
     "start_time": "2020-11-11T08:49:10.107534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0004d9e33</td>\n",
       "      <td>0.001305</td>\n",
       "      <td>0.001102</td>\n",
       "      <td>0.001815</td>\n",
       "      <td>0.012368</td>\n",
       "      <td>0.020106</td>\n",
       "      <td>0.004711</td>\n",
       "      <td>0.002353</td>\n",
       "      <td>0.007398</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001598</td>\n",
       "      <td>0.001512</td>\n",
       "      <td>0.003004</td>\n",
       "      <td>0.002510</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000983</td>\n",
       "      <td>0.001736</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>0.004006</td>\n",
       "      <td>0.002056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_001897cda</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0.001185</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.000972</td>\n",
       "      <td>0.001546</td>\n",
       "      <td>0.003025</td>\n",
       "      <td>0.005415</td>\n",
       "      <td>0.020127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.002399</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.007429</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.002045</td>\n",
       "      <td>0.000944</td>\n",
       "      <td>0.005571</td>\n",
       "      <td>0.002427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_002429b5b</td>\n",
       "      <td>0.001224</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>0.002940</td>\n",
       "      <td>0.016178</td>\n",
       "      <td>0.031764</td>\n",
       "      <td>0.004513</td>\n",
       "      <td>0.005201</td>\n",
       "      <td>0.003832</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002237</td>\n",
       "      <td>0.001762</td>\n",
       "      <td>0.004485</td>\n",
       "      <td>0.003175</td>\n",
       "      <td>0.004306</td>\n",
       "      <td>0.000985</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>0.005018</td>\n",
       "      <td>0.003306</td>\n",
       "      <td>0.004417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00276f245</td>\n",
       "      <td>0.001541</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>0.001966</td>\n",
       "      <td>0.010102</td>\n",
       "      <td>0.010635</td>\n",
       "      <td>0.004972</td>\n",
       "      <td>0.002246</td>\n",
       "      <td>0.004771</td>\n",
       "      <td>0.000912</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001478</td>\n",
       "      <td>0.001845</td>\n",
       "      <td>0.003487</td>\n",
       "      <td>0.019258</td>\n",
       "      <td>0.011883</td>\n",
       "      <td>0.001630</td>\n",
       "      <td>0.003380</td>\n",
       "      <td>0.002253</td>\n",
       "      <td>0.002232</td>\n",
       "      <td>0.003078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_0027f1083</td>\n",
       "      <td>0.002004</td>\n",
       "      <td>0.001451</td>\n",
       "      <td>0.002405</td>\n",
       "      <td>0.010681</td>\n",
       "      <td>0.020395</td>\n",
       "      <td>0.004446</td>\n",
       "      <td>0.005799</td>\n",
       "      <td>0.002602</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>0.001394</td>\n",
       "      <td>0.002982</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>0.001025</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>0.001541</td>\n",
       "      <td>0.002329</td>\n",
       "      <td>0.000944</td>\n",
       "      <td>0.001576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>id_ff7004b87</td>\n",
       "      <td>0.001317</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>0.002754</td>\n",
       "      <td>0.003356</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>0.001241</td>\n",
       "      <td>0.002942</td>\n",
       "      <td>0.001923</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>0.005763</td>\n",
       "      <td>0.003879</td>\n",
       "      <td>0.115764</td>\n",
       "      <td>0.006209</td>\n",
       "      <td>0.001207</td>\n",
       "      <td>0.006215</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>0.002802</td>\n",
       "      <td>0.001922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>id_ff925dd0d</td>\n",
       "      <td>0.003969</td>\n",
       "      <td>0.002901</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>0.006031</td>\n",
       "      <td>0.022778</td>\n",
       "      <td>0.005112</td>\n",
       "      <td>0.004133</td>\n",
       "      <td>0.003337</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000925</td>\n",
       "      <td>0.001102</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>0.003256</td>\n",
       "      <td>0.001155</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001793</td>\n",
       "      <td>0.001482</td>\n",
       "      <td>0.001127</td>\n",
       "      <td>0.001415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3979</th>\n",
       "      <td>id_ffb710450</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>0.000880</td>\n",
       "      <td>0.008758</td>\n",
       "      <td>0.025717</td>\n",
       "      <td>0.004435</td>\n",
       "      <td>0.003086</td>\n",
       "      <td>0.004109</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>0.000939</td>\n",
       "      <td>0.001794</td>\n",
       "      <td>0.002189</td>\n",
       "      <td>0.001083</td>\n",
       "      <td>0.000857</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.001269</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>0.001454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>id_ffbb869f2</td>\n",
       "      <td>0.002443</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.016420</td>\n",
       "      <td>0.039411</td>\n",
       "      <td>0.008577</td>\n",
       "      <td>0.004178</td>\n",
       "      <td>0.003121</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000849</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>0.003563</td>\n",
       "      <td>0.001965</td>\n",
       "      <td>0.001330</td>\n",
       "      <td>0.001032</td>\n",
       "      <td>0.001624</td>\n",
       "      <td>0.001526</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.002973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3981</th>\n",
       "      <td>id_ffd5800b6</td>\n",
       "      <td>0.001638</td>\n",
       "      <td>0.001691</td>\n",
       "      <td>0.002210</td>\n",
       "      <td>0.012132</td>\n",
       "      <td>0.016702</td>\n",
       "      <td>0.004743</td>\n",
       "      <td>0.002793</td>\n",
       "      <td>0.011560</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001052</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>0.002126</td>\n",
       "      <td>0.003682</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>0.001232</td>\n",
       "      <td>0.001809</td>\n",
       "      <td>0.002583</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3982 rows Ã— 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
       "0     id_0004d9e33                     0.001305                0.001102   \n",
       "1     id_001897cda                     0.000703                0.000872   \n",
       "2     id_002429b5b                     0.001224                0.000757   \n",
       "3     id_00276f245                     0.001541                0.000807   \n",
       "4     id_0027f1083                     0.002004                0.001451   \n",
       "...            ...                          ...                     ...   \n",
       "3977  id_ff7004b87                     0.001317                0.001079   \n",
       "3978  id_ff925dd0d                     0.003969                0.002901   \n",
       "3979  id_ffb710450                     0.001952                0.001129   \n",
       "3980  id_ffbb869f2                     0.002443                0.001796   \n",
       "3981  id_ffd5800b6                     0.001638                0.001691   \n",
       "\n",
       "      acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
       "0           0.001815                        0.012368   \n",
       "1           0.001185                        0.001316   \n",
       "2           0.002940                        0.016178   \n",
       "3           0.001966                        0.010102   \n",
       "4           0.002405                        0.010681   \n",
       "...              ...                             ...   \n",
       "3977        0.001613                        0.002754   \n",
       "3978        0.000853                        0.006031   \n",
       "3979        0.000880                        0.008758   \n",
       "3980        0.001204                        0.016420   \n",
       "3981        0.002210                        0.012132   \n",
       "\n",
       "      acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n",
       "0                              0.020106                        0.004711   \n",
       "1                              0.000972                        0.001546   \n",
       "2                              0.031764                        0.004513   \n",
       "3                              0.010635                        0.004972   \n",
       "4                              0.020395                        0.004446   \n",
       "...                                 ...                             ...   \n",
       "3977                           0.003356                        0.001176   \n",
       "3978                           0.022778                        0.005112   \n",
       "3979                           0.025717                        0.004435   \n",
       "3980                           0.039411                        0.008577   \n",
       "3981                           0.016702                        0.004743   \n",
       "\n",
       "      adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n",
       "0                       0.002353                       0.007398   \n",
       "1                       0.003025                       0.005415   \n",
       "2                       0.005201                       0.003832   \n",
       "3                       0.002246                       0.004771   \n",
       "4                       0.005799                       0.002602   \n",
       "...                          ...                            ...   \n",
       "3977                    0.001241                       0.002942   \n",
       "3978                    0.004133                       0.003337   \n",
       "3979                    0.003086                       0.004109   \n",
       "3980                    0.004178                       0.003121   \n",
       "3981                    0.002793                       0.011560   \n",
       "\n",
       "      adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                       0.000524  ...                               0.001598   \n",
       "1                       0.020127  ...                               0.001476   \n",
       "2                       0.000959  ...                               0.002237   \n",
       "3                       0.000912  ...                               0.001478   \n",
       "4                       0.000550  ...                               0.001423   \n",
       "...                          ...  ...                                    ...   \n",
       "3977                    0.001923  ...                               0.001613   \n",
       "3978                    0.000743  ...                               0.000925   \n",
       "3979                    0.000483  ...                               0.000664   \n",
       "3980                    0.000706  ...                               0.000849   \n",
       "3981                    0.000649  ...                               0.001052   \n",
       "\n",
       "      trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0         0.001512         0.003004           0.002510   \n",
       "1         0.002399         0.001709           0.000463   \n",
       "2         0.001762         0.004485           0.003175   \n",
       "3         0.001845         0.003487           0.019258   \n",
       "4         0.001394         0.002982           0.001961   \n",
       "...            ...              ...                ...   \n",
       "3977      0.005763         0.003879           0.115764   \n",
       "3978      0.001102         0.002008           0.003256   \n",
       "3979      0.000939         0.001794           0.002189   \n",
       "3980      0.000762         0.003563           0.001965   \n",
       "3981      0.002864         0.002126           0.003682   \n",
       "\n",
       "      tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                      0.000689                               0.000983   \n",
       "1                      0.007429                               0.000997   \n",
       "2                      0.004306                               0.000985   \n",
       "3                      0.011883                               0.001630   \n",
       "4                      0.001025                               0.001095   \n",
       "...                         ...                                    ...   \n",
       "3977                   0.006209                               0.001207   \n",
       "3978                   0.001155                               0.001314   \n",
       "3979                   0.001083                               0.000857   \n",
       "3980                   0.001330                               0.001032   \n",
       "3981                   0.001360                               0.001232   \n",
       "\n",
       "      vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0            0.001736   0.002389                    0.004006       0.002056  \n",
       "1            0.002045   0.000944                    0.005571       0.002427  \n",
       "2            0.003513   0.005018                    0.003306       0.004417  \n",
       "3            0.003380   0.002253                    0.002232       0.003078  \n",
       "4            0.001541   0.002329                    0.000944       0.001576  \n",
       "...               ...        ...                         ...            ...  \n",
       "3977         0.006215   0.001390                    0.002802       0.001922  \n",
       "3978         0.001793   0.001482                    0.001127       0.001415  \n",
       "3979         0.000876   0.001269                    0.000829       0.001454  \n",
       "3980         0.001624   0.001526                    0.001096       0.002973  \n",
       "3981         0.001809   0.002583                    0.001316       0.001671  \n",
       "\n",
       "[3982 rows x 207 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T08:50:23.604717Z",
     "iopub.status.busy": "2020-11-11T08:50:23.601559Z",
     "iopub.status.idle": "2020-11-11T08:50:26.002857Z",
     "shell.execute_reply": "2020-11-11T08:50:26.001634Z"
    },
    "papermill": {
     "duration": 16.925683,
     "end_time": "2020-11-11T08:50:26.003039",
     "exception": false,
     "start_time": "2020-11-11T08:50:09.077356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set ctl_vehicle to 0\n",
    "sub.iloc[test_features['cp_type'] == 'ctl_vehicle', 1:] = 0\n",
    "\n",
    "# Save Submission\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T08:50:54.604220Z",
     "iopub.status.busy": "2020-11-11T08:50:54.602918Z",
     "iopub.status.idle": "2020-11-11T08:50:54.644669Z",
     "shell.execute_reply": "2020-11-11T08:50:54.645356Z"
    },
    "papermill": {
     "duration": 14.756009,
     "end_time": "2020-11-11T08:50:54.645529",
     "exception": false,
     "start_time": "2020-11-11T08:50:39.889520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0004d9e33</td>\n",
       "      <td>0.001305</td>\n",
       "      <td>0.001102</td>\n",
       "      <td>0.001815</td>\n",
       "      <td>0.012368</td>\n",
       "      <td>0.020106</td>\n",
       "      <td>0.004711</td>\n",
       "      <td>0.002353</td>\n",
       "      <td>0.007398</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001598</td>\n",
       "      <td>0.001512</td>\n",
       "      <td>0.003004</td>\n",
       "      <td>0.002510</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000983</td>\n",
       "      <td>0.001736</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>0.004006</td>\n",
       "      <td>0.002056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_001897cda</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0.001185</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.000972</td>\n",
       "      <td>0.001546</td>\n",
       "      <td>0.003025</td>\n",
       "      <td>0.005415</td>\n",
       "      <td>0.020127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.002399</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.007429</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.002045</td>\n",
       "      <td>0.000944</td>\n",
       "      <td>0.005571</td>\n",
       "      <td>0.002427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_002429b5b</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00276f245</td>\n",
       "      <td>0.001541</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>0.001966</td>\n",
       "      <td>0.010102</td>\n",
       "      <td>0.010635</td>\n",
       "      <td>0.004972</td>\n",
       "      <td>0.002246</td>\n",
       "      <td>0.004771</td>\n",
       "      <td>0.000912</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001478</td>\n",
       "      <td>0.001845</td>\n",
       "      <td>0.003487</td>\n",
       "      <td>0.019258</td>\n",
       "      <td>0.011883</td>\n",
       "      <td>0.001630</td>\n",
       "      <td>0.003380</td>\n",
       "      <td>0.002253</td>\n",
       "      <td>0.002232</td>\n",
       "      <td>0.003078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_0027f1083</td>\n",
       "      <td>0.002004</td>\n",
       "      <td>0.001451</td>\n",
       "      <td>0.002405</td>\n",
       "      <td>0.010681</td>\n",
       "      <td>0.020395</td>\n",
       "      <td>0.004446</td>\n",
       "      <td>0.005799</td>\n",
       "      <td>0.002602</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>0.001394</td>\n",
       "      <td>0.002982</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>0.001025</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>0.001541</td>\n",
       "      <td>0.002329</td>\n",
       "      <td>0.000944</td>\n",
       "      <td>0.001576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>id_ff7004b87</td>\n",
       "      <td>0.001317</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>0.002754</td>\n",
       "      <td>0.003356</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>0.001241</td>\n",
       "      <td>0.002942</td>\n",
       "      <td>0.001923</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>0.005763</td>\n",
       "      <td>0.003879</td>\n",
       "      <td>0.115764</td>\n",
       "      <td>0.006209</td>\n",
       "      <td>0.001207</td>\n",
       "      <td>0.006215</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>0.002802</td>\n",
       "      <td>0.001922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>id_ff925dd0d</td>\n",
       "      <td>0.003969</td>\n",
       "      <td>0.002901</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>0.006031</td>\n",
       "      <td>0.022778</td>\n",
       "      <td>0.005112</td>\n",
       "      <td>0.004133</td>\n",
       "      <td>0.003337</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000925</td>\n",
       "      <td>0.001102</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>0.003256</td>\n",
       "      <td>0.001155</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.001793</td>\n",
       "      <td>0.001482</td>\n",
       "      <td>0.001127</td>\n",
       "      <td>0.001415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3979</th>\n",
       "      <td>id_ffb710450</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>0.000880</td>\n",
       "      <td>0.008758</td>\n",
       "      <td>0.025717</td>\n",
       "      <td>0.004435</td>\n",
       "      <td>0.003086</td>\n",
       "      <td>0.004109</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>0.000939</td>\n",
       "      <td>0.001794</td>\n",
       "      <td>0.002189</td>\n",
       "      <td>0.001083</td>\n",
       "      <td>0.000857</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.001269</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>0.001454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>id_ffbb869f2</td>\n",
       "      <td>0.002443</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.016420</td>\n",
       "      <td>0.039411</td>\n",
       "      <td>0.008577</td>\n",
       "      <td>0.004178</td>\n",
       "      <td>0.003121</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000849</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>0.003563</td>\n",
       "      <td>0.001965</td>\n",
       "      <td>0.001330</td>\n",
       "      <td>0.001032</td>\n",
       "      <td>0.001624</td>\n",
       "      <td>0.001526</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.002973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3981</th>\n",
       "      <td>id_ffd5800b6</td>\n",
       "      <td>0.001638</td>\n",
       "      <td>0.001691</td>\n",
       "      <td>0.002210</td>\n",
       "      <td>0.012132</td>\n",
       "      <td>0.016702</td>\n",
       "      <td>0.004743</td>\n",
       "      <td>0.002793</td>\n",
       "      <td>0.011560</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001052</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>0.002126</td>\n",
       "      <td>0.003682</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>0.001232</td>\n",
       "      <td>0.001809</td>\n",
       "      <td>0.002583</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.001671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3982 rows Ã— 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
       "0     id_0004d9e33                     0.001305                0.001102   \n",
       "1     id_001897cda                     0.000703                0.000872   \n",
       "2     id_002429b5b                     0.000000                0.000000   \n",
       "3     id_00276f245                     0.001541                0.000807   \n",
       "4     id_0027f1083                     0.002004                0.001451   \n",
       "...            ...                          ...                     ...   \n",
       "3977  id_ff7004b87                     0.001317                0.001079   \n",
       "3978  id_ff925dd0d                     0.003969                0.002901   \n",
       "3979  id_ffb710450                     0.001952                0.001129   \n",
       "3980  id_ffbb869f2                     0.002443                0.001796   \n",
       "3981  id_ffd5800b6                     0.001638                0.001691   \n",
       "\n",
       "      acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
       "0           0.001815                        0.012368   \n",
       "1           0.001185                        0.001316   \n",
       "2           0.000000                        0.000000   \n",
       "3           0.001966                        0.010102   \n",
       "4           0.002405                        0.010681   \n",
       "...              ...                             ...   \n",
       "3977        0.001613                        0.002754   \n",
       "3978        0.000853                        0.006031   \n",
       "3979        0.000880                        0.008758   \n",
       "3980        0.001204                        0.016420   \n",
       "3981        0.002210                        0.012132   \n",
       "\n",
       "      acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n",
       "0                              0.020106                        0.004711   \n",
       "1                              0.000972                        0.001546   \n",
       "2                              0.000000                        0.000000   \n",
       "3                              0.010635                        0.004972   \n",
       "4                              0.020395                        0.004446   \n",
       "...                                 ...                             ...   \n",
       "3977                           0.003356                        0.001176   \n",
       "3978                           0.022778                        0.005112   \n",
       "3979                           0.025717                        0.004435   \n",
       "3980                           0.039411                        0.008577   \n",
       "3981                           0.016702                        0.004743   \n",
       "\n",
       "      adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n",
       "0                       0.002353                       0.007398   \n",
       "1                       0.003025                       0.005415   \n",
       "2                       0.000000                       0.000000   \n",
       "3                       0.002246                       0.004771   \n",
       "4                       0.005799                       0.002602   \n",
       "...                          ...                            ...   \n",
       "3977                    0.001241                       0.002942   \n",
       "3978                    0.004133                       0.003337   \n",
       "3979                    0.003086                       0.004109   \n",
       "3980                    0.004178                       0.003121   \n",
       "3981                    0.002793                       0.011560   \n",
       "\n",
       "      adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                       0.000524  ...                               0.001598   \n",
       "1                       0.020127  ...                               0.001476   \n",
       "2                       0.000000  ...                               0.000000   \n",
       "3                       0.000912  ...                               0.001478   \n",
       "4                       0.000550  ...                               0.001423   \n",
       "...                          ...  ...                                    ...   \n",
       "3977                    0.001923  ...                               0.001613   \n",
       "3978                    0.000743  ...                               0.000925   \n",
       "3979                    0.000483  ...                               0.000664   \n",
       "3980                    0.000706  ...                               0.000849   \n",
       "3981                    0.000649  ...                               0.001052   \n",
       "\n",
       "      trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0         0.001512         0.003004           0.002510   \n",
       "1         0.002399         0.001709           0.000463   \n",
       "2         0.000000         0.000000           0.000000   \n",
       "3         0.001845         0.003487           0.019258   \n",
       "4         0.001394         0.002982           0.001961   \n",
       "...            ...              ...                ...   \n",
       "3977      0.005763         0.003879           0.115764   \n",
       "3978      0.001102         0.002008           0.003256   \n",
       "3979      0.000939         0.001794           0.002189   \n",
       "3980      0.000762         0.003563           0.001965   \n",
       "3981      0.002864         0.002126           0.003682   \n",
       "\n",
       "      tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                      0.000689                               0.000983   \n",
       "1                      0.007429                               0.000997   \n",
       "2                      0.000000                               0.000000   \n",
       "3                      0.011883                               0.001630   \n",
       "4                      0.001025                               0.001095   \n",
       "...                         ...                                    ...   \n",
       "3977                   0.006209                               0.001207   \n",
       "3978                   0.001155                               0.001314   \n",
       "3979                   0.001083                               0.000857   \n",
       "3980                   0.001330                               0.001032   \n",
       "3981                   0.001360                               0.001232   \n",
       "\n",
       "      vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0            0.001736   0.002389                    0.004006       0.002056  \n",
       "1            0.002045   0.000944                    0.005571       0.002427  \n",
       "2            0.000000   0.000000                    0.000000       0.000000  \n",
       "3            0.003380   0.002253                    0.002232       0.003078  \n",
       "4            0.001541   0.002329                    0.000944       0.001576  \n",
       "...               ...        ...                         ...            ...  \n",
       "3977         0.006215   0.001390                    0.002802       0.001922  \n",
       "3978         0.001793   0.001482                    0.001127       0.001415  \n",
       "3979         0.000876   0.001269                    0.000829       0.001454  \n",
       "3980         0.001624   0.001526                    0.001096       0.002973  \n",
       "3981         0.001809   0.002583                    0.001316       0.001671  \n",
       "\n",
       "[3982 rows x 207 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "papermill": {
   "duration": 3964.293061,
   "end_time": "2020-11-11T08:51:10.704042",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-11T07:45:06.410981",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
